{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import pprint\n",
    "from IPython.display import HTML\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load pre-trained embedding. See readme for training your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from code.feiii_transformers import _EmbeddingHolder\n",
    "embedding = _EmbeddingHolder()\n",
    "embedding.load('embedding')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "reading file STATE-STREET_2016.csv with 23 entries.\n",
      "reading file STATE-STREET_2014.csv with 26 entries.\n",
      "reading file PNC_2016.csv with 33 entries.\n",
      "reading file PNC_2014.csv with 38 entries.\n",
      "reading file JPM_2016.csv with 52 entries.\n",
      "reading file COMERICA_2016.csv with 11 entries.\n",
      "reading file FIFTH-THIRD_2014.csv with 36 entries.\n",
      "reading file CITIGROUP_2014.csv with 52 entries.\n",
      "reading file AMERICAN-EXPRESS_2015.csv with 11 entries.\n",
      "reading file BANK-OF-AMERICA_2015.csv with 74 entries.\n",
      "reading file ALLY_2016.csv with 44 entries.\n",
      "reading file CITIGROUP_2016.csv with 50 entries.\n",
      "reading file ALLY_2014.csv with 40 entries.\n",
      "reading file SUNTRUST_2013.csv with 35 entries.\n",
      "reading file DISCOVER_2014.csv with 41 entries.\n",
      "reading file MORGAN-STANLEY_2015.csv with 128 entries.\n",
      "reading file SUNTRUST_2016.csv with 27 entries.\n",
      "reading file BBT_2014.csv with 14 entries.\n",
      "reading file GENERAL-ELECTRIC_2013.csv with 21 entries.\n",
      "reading file FIFTH-THIRD_2015.csv with 46 entries.\n",
      "reading file CAPITAL-ONE_2013.csv with 25 entries.\n",
      "reading file BANK-OF-AMERICA_2013.csv with 88 entries.\n",
      "reading file NORTHERN-TRUST_2013.csv with 18 entries.\n",
      "reading file MT_2015.csv with 21 entries.\n",
      "reading file MT_2013.csv with 21 entries.\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><th></th><th>TRAINING</th><th>TESTING SET</th></tr><tr><td>#ROWS</td><td>975</td><td>900</td></tr><tr><td>ROLES</td><td>{'affiliate': 186,<br /> 'agent': 61,<br /> 'counterpart': 64,<br /> 'guarantor': 34,<br /> 'insurer': 19,<br /> 'issuer': 129,<br /> 'seller': 20,<br /> 'servicer': 21,<br /> 'trustee': 420,<br /> 'underwriter': 21}</td><td>{'affiliate': 129,<br /> 'agent': 40,<br /> 'counterpart': 108,<br /> 'guarantor': 28,<br /> 'insurer': 47,<br /> 'issuer': 98,<br /> 'seller': 49,<br /> 'servicer': 57,<br /> 'trustee': 304,<br /> 'underwriter': 40}</td></tr><tr><td>DOCUMENTS</td><td>{'1393612-2013-FY': 41,<br /> '19617-2015-FY': 52,<br /> '28412-2015-FY': 11,<br /> '35527-2013-FY': 36,<br /> '35527-2014-FY': 46,<br /> '36270-m&t-2012': 21,<br /> '36270-m&t-2014': 21,<br /> '40545-2012-FY': 21,<br /> '40729-2013-FY': 40,<br /> '40729-2015-FY': 44,<br /> '4962-2014-FY': 11,<br /> '70858-2012-FY': 88,<br /> '70858-2014-FY': 74,<br /> '713676-2013-FY': 38,<br /> '713676-2015-FY': 33,<br /> '73124-2012-FY': 18,<br /> '750556-2012-FY': 35,<br /> '750556-2015-FY': 27,<br /> '831001-2013-FY': 52,<br /> '831001-2015-FY': 50,<br /> '895421-2014-FY': 128,<br /> '92230-2013-FY': 14,<br /> '927628-2012-FY': 25,<br /> '93751-2013-FY': 26,<br /> '93751-2015-FY': 23}</td><td>{'1026214-2011-Q2': 64,<br /> '1026214-2013-FY': 99,<br /> '109380-2014-FY': 13,<br /> '1390777-2015-Q1': 26,<br /> '1393612-2010-FY': 11,<br /> '19617-2011-FY': 67,<br /> '28412-2012-FY': 11,<br /> '310522-2012-FY': 59,<br /> '310522-2013-Q2': 21,<br /> '316709-2015-FY': 14,<br /> '36104-_2015-FY': 8,<br /> '36270-m&t-2010': 18,<br /> '40545-2015-FY': 27,<br /> '40729-2012-Q3': 23,<br /> '4962-2015-FY': 19,<br /> '70858-2013-FY': 81,<br /> '713676-2014-FY': 33,<br /> '73124-2015-FY': 28,<br /> '831001-2011-FY': 37,<br /> '886982-2013-FY': 36,<br /> '895421-2015-FY': 134,<br /> '91576-2012-FY': 10,<br /> '92230-2010-FY': 21,<br /> '927628-2010-FY': 20,<br /> '93751-2010-FY': 20}</td></tr><tr><td>COMPANIES</td><td>{'AMERICAN EXPRESS CO': 11,<br /> 'Ally Financial Inc': 84,<br /> 'BANK OF AMERICA CORP': 162,<br /> 'BB&T CORP': 14,<br /> 'CAPITAL ONE FINANCIAL CORP': 25,<br /> 'CITIGROUP INC': 102,<br /> 'COMERICA INC': 11,<br /> 'Discover Financial Services': 41,<br /> 'FIFTH THIRD BANCORP': 82,<br /> 'GENERAL ELECTRIC CO': 21,<br /> 'JPMORGAN CHASE & CO': 52,<br /> 'M&T BANK CORP': 42,<br /> 'MORGAN STANLEY': 128,<br /> 'NORTHERN TRUST CORP': 18,<br /> 'PNC FINANCIAL SERVICES GROUP INC': 71,<br /> 'STATE STREET CORP': 49,<br /> 'SUNTRUST BANKS INC': 62}</td><td>{'AMERICAN EXPRESS CO': 19,<br /> 'Ally Financial Inc': 23,<br /> 'BANK OF AMERICA CORP': 81,<br /> 'BB&T CORP': 21,<br /> 'Bank of New York Mellon Corp': 26,<br /> 'CAPITAL ONE FINANCIAL CORP': 20,<br /> 'CITIGROUP INC': 37,<br /> 'COMERICA INC': 11,<br /> 'Discover Financial Services': 11,<br /> 'FEDERAL_HOME_LOAN_MORTGAGE_CORP': 163,<br /> 'FEDERAL_NATIONAL_MORTGAGE_ASSOCIATION_FANNIE_MAE': 80,<br /> 'GENERAL ELECTRIC CO': 27,<br /> 'GOLDMAN SACHS GROUP INC': 36,<br /> 'JPMORGAN CHASE & CO': 67,<br /> 'KEYCORP': 10,<br /> 'M&T BANK CORP': 18,<br /> 'MORGAN STANLEY': 134,<br /> 'NORTHERN TRUST CORP': 28,<br /> 'PNC FINANCIAL SERVICES GROUP INC': 33,<br /> 'SCHWAB_CHARLES_CORP ': 14,<br /> 'STATE STREET CORP': 20,<br /> 'US_BANCORP': 8,<br /> 'ZIONS BANCORPORATION': 13}</td></tr><tr><td>Expert ratings</td><td>RATING_EXPERT_1 Counter({nan: 566, 'Highly relevant': 149, 'Neutral': 139, 'Relevant': 93, 'Irrelevant': 28})<br/>RATING_EXPERT_1.1 Counter({nan: 749, 'Highly relevant': 101, 'Neutral': 83, 'Relevant': 35, 'Irrelevant': 7})<br/>RATING_EXPERT_10 Counter({nan: 955, 'Relevant': 20})<br/>RATING_EXPERT_2 Counter({nan: 609, 'Relevant': 163, 'Neutral': 131, 'Highly relevant': 58, 'Irrelevant': 14})<br/>RATING_EXPERT_3 Counter({nan: 915, 'Irrelevant': 29, 'Neutral': 15, 'Highly relevant': 8, 'Relevant': 8})<br/>RATING_EXPERT_4 Counter({nan: 940, 'Relevant': 23, 'Neutral': 5, 'Highly relevant': 5, 'Irrelevant': 2})<br/>RATING_EXPERT_5 Counter({nan: 895, 'Neutral': 41, 'Relevant': 29, 'Highly relevant': 7, 'Irrelevant': 3})<br/>RATING_EXPERT_6 Counter({nan: 915, 'Relevant': 34, 'Highly relevant': 10, 'Irrelevant': 10, 'Neutral': 6})<br/>RATING_EXPERT_7 Counter({nan: 900, 'Neutral': 36, 'Relevant': 27, 'Highly relevant': 10, 'Irrelevant': 2})<br/>RATING_EXPERT_9 Counter({nan: 901, 'Highly relevant': 62, 'Irrelevant': 10, 'Neutral': 1, 'Relevant': 1})<br/></td><td>Counter({'relevant': 369, 'highly': 309, 'neutral': 142, 'irrelevant': 80})</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from code.feiii_experiment import evaluate, kfold\n",
    "from code.feiii_data import DataHolder\n",
    "from code.feiii_pipeline import FeiiiPipeline\n",
    "\n",
    "\n",
    "def pp(obj):\n",
    "    return pprint.pformat(obj).replace('\\n','<br />')\n",
    "\n",
    "data = DataHolder(eval_docs=2)\n",
    "print('done')\n",
    "\n",
    "out = '<table><tr><th></th><th>TRAINING</th><th>TESTING SET</th></tr>'\n",
    "out+= '<tr><td>#ROWS</td><td>'+str(len(data.train_full))+'</td><td>'+str(len(data.test))+'</td></tr>'\n",
    "out+= '<tr><td>ROLES</td><td>'+pp(dict(Counter(data.train_full['grp'])))+'</td><td>'+pp(dict(Counter(data.test['grp'])))+'</td></tr>'\n",
    "out+= '<tr><td>DOCUMENTS</td><td>'+pp(dict(Counter(data.train_full['SOURCE'])))+'</td><td>'+pp(dict(Counter(data.test['SOURCE'])))+'</td></tr>'\n",
    "out+= '<tr><td>COMPANIES</td><td>'+pp(dict(Counter(data.train_full['FILER_NAME'])))+'</td><td>'+pp(dict(Counter(data.test['FILER_NAME'])))+'</td></tr>'\n",
    "out+= '<tr><td>Expert ratings</td><td>'\n",
    "tmp = Counter(data.train_full['rating'])\n",
    "out+= \"ALL: [H]{:_>4d} [R]{:_>4d} [N]{:_>4d} [I]{:_>4d}<br/>\".format(\n",
    "    tmp.get('highly',0),tmp.get('relevant',0),tmp.get('neutral',0),tmp.get('irrelevant',0))\n",
    "for c in data.train_full.filter(regex=(\"RATING\")):\n",
    "    tmp = Counter(data.train_full[c])\n",
    "    out+=\"[H]{:_>3d} [R]{:_>3d} [N]{:_>3d} [I]{:_>3d} [x]{:_>3d} ({})<br/>\".format(\n",
    "        tmp.get(\"Highly relevant\", 0), tmp.get(\"Relevant\", 0),\n",
    "        tmp.get(\"Neutral\", 0),tmp.get(\"Irrelevant\", 0),\n",
    "        tmp.get(np.nan, 0), c)\n",
    "out+= '</td><td>'\n",
    "tmp = Counter(data.test['rating'])\n",
    "out+= \"ALL: [H]{:_>4d} [R]{:_>4d} [N]{:_>4d} [I]{:_>4d}<br/>\".format(\n",
    "    tmp.get('highly',0),tmp.get('relevant',0),tmp.get('neutral',0),tmp.get('irrelevant',0))\n",
    "out+= '</td></tr>'\n",
    "out+= '</table>'\n",
    "\n",
    "HTML(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the following line in case of errors during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.shuffle_train_eval(n_docs_eval=0, max_tries=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items in training set: 910 (93.33%)\n",
      "Items in eval set: 65\n",
      "Items in test set: 900\n",
      " = 1875\n",
      "Number of source documents: 50 total, 23 train, 2 eval 25 test\n",
      "Absolute (training): IR 74.00, N 289.00, R 259.00, HR 288.00\n",
      "Relative (training): IR 0.08, N 0.32, R 0.28, HR 0.32\n",
      "Absolute (eval): IR 16.00, N 18.00, R 24.00, HR 7.00\n",
      "Relative (eval): IR 0.25, N 0.28, R 0.37, HR 0.11\n",
      "Role samples for GUARANTOR in train: 22, eval: 12, test: 28\n",
      "Role samples for SERVICER in train: 21, eval: 0, test: 57\n",
      "Role samples for AGENT in train: 56, eval: 5, test: 40\n",
      "Role samples for COUNTERPART in train: 63, eval: 1, test: 108\n",
      "Role samples for TRUSTEE in train: 412, eval: 8, test: 304\n",
      "Role samples for ISSUER in train: 122, eval: 7, test: 98\n",
      "Role samples for UNDERWRITER in train: 14, eval: 7, test: 40\n",
      "Role samples for SELLER in train: 20, eval: 0, test: 49\n",
      "Role samples for INSURER in train: 19, eval: 0, test: 47\n",
      "Role samples for AFFILIATE in train: 161, eval: 25, test: 129\n",
      "=== GUARANTOR ======\n",
      "Items in training set: 22 (64.71%)\n",
      "Items in eval set: 12\n",
      "Items in test set: 28\n",
      " = 62\n",
      "Number of source documents: 15 total, 5 train, 1 eval 9 test\n",
      "Absolute (training): IR 1.00, N 3.00, R 10.00, HR 8.00\n",
      "Relative (training): IR 0.05, N 0.14, R 0.45, HR 0.36\n",
      "Absolute (eval): IR 0.00, N 0.00, R 12.00, HR 0.00\n",
      "Relative (eval): IR 0.00, N 0.00, R 1.00, HR 0.00\n",
      "Role samples for GUARANTOR in train: 22, eval: 12, test: 28\n",
      "NDCG after 100x random order:\n",
      " > mean ndcg = 1.0 | std = 0.0\n",
      "NDCG for worst case (inverted best) order:\n",
      " > ndcg = 1.0\n",
      "Accuracy | role : 0.5\n",
      "Accuracy | full : 0.107142857143\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " irrelevant       0.00      0.00      0.00         0\n",
      "    neutral       0.00      0.00      0.00         3\n",
      "   relevant       1.00      0.14      0.24        22\n",
      "     highly       0.00      0.00      0.00         3\n",
      "\n",
      "avg / total       0.79      0.11      0.19        28\n",
      "\n",
      "[[ 0  0  0  0]\n",
      " [ 3  0  0  0]\n",
      " [15  4  3  0]\n",
      " [ 3  0  0  0]]\n",
      "> NDCG Score | role | categ  | 0.91730\n",
      "> NDCG Score | role | proba* | 0.92293\n",
      "> NDCG Score | full | categ  | 0.89919\n",
      "> NDCG Score | full | proba* | 0.89919\n",
      "=== AGENT ======\n",
      "Items in training set: 56 (91.80%)\n",
      "Items in eval set: 5\n",
      "Items in test set: 40\n",
      " = 101\n",
      "Number of source documents: 25 total, 14 train, 2 eval 9 test\n",
      "Absolute (training): IR 3.00, N 33.00, R 16.00, HR 4.00\n",
      "Relative (training): IR 0.05, N 0.59, R 0.29, HR 0.07\n",
      "Absolute (eval): IR 0.00, N 2.00, R 2.00, HR 1.00\n",
      "Relative (eval): IR 0.00, N 0.40, R 0.40, HR 0.20\n",
      "Role samples for AGENT in train: 56, eval: 5, test: 40\n",
      "NDCG after 100x random order:\n",
      " > mean ndcg = 0.891867374681 | std = 0.0602849131143\n",
      "NDCG for worst case (inverted best) order:\n",
      " > ndcg = 0.772173977441\n",
      "Accuracy | role : 0.475\n",
      "Accuracy | full : 0.225\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " irrelevant       0.10      0.50      0.16         4\n",
      "    neutral       0.00      0.00      0.00         8\n",
      "   relevant       0.50      0.47      0.48        15\n",
      "     highly       0.00      0.00      0.00        13\n",
      "\n",
      "avg / total       0.20      0.23      0.20        40\n",
      "\n",
      "[[ 2  0  2  0]\n",
      " [ 4  0  4  0]\n",
      " [ 5  3  7  0]\n",
      " [10  2  1  0]]\n",
      "> NDCG Score | role | categ  | 0.91605\n",
      "> NDCG Score | role | proba* | 0.77329\n",
      "> NDCG Score | full | categ  | 0.86530\n",
      "> NDCG Score | full | proba* | 0.80170\n",
      "=== COUNTERPART ======\n",
      "Items in training set: 63 (98.44%)\n",
      "Items in eval set: 1\n",
      "Items in test set: 108\n",
      " = 172\n",
      "Number of source documents: 31 total, 16 train, 1 eval 14 test\n",
      "Absolute (training): IR 6.00, N 12.00, R 29.00, HR 16.00\n",
      "Relative (training): IR 0.10, N 0.19, R 0.46, HR 0.25\n",
      "Absolute (eval): IR 0.00, N 0.00, R 1.00, HR 0.00\n",
      "Relative (eval): IR 0.00, N 0.00, R 1.00, HR 0.00\n",
      "Role samples for COUNTERPART in train: 63, eval: 1, test: 108\n",
      "NDCG after 100x random order:\n",
      " > mean ndcg = 1.0 | std = 0.0\n",
      "NDCG for worst case (inverted best) order:\n",
      " > ndcg = 1.0\n",
      "Accuracy | role : 0.240740740741\n",
      "Accuracy | full : 0.296296296296\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " irrelevant       0.20      0.50      0.28        18\n",
      "    neutral       0.00      0.00      0.00        17\n",
      "   relevant       0.37      0.58      0.45        38\n",
      "     highly       1.00      0.03      0.06        35\n",
      "\n",
      "avg / total       0.49      0.30      0.22       108\n",
      "\n",
      "[[ 9  0  9  0]\n",
      " [ 7  0 10  0]\n",
      " [15  1 22  0]\n",
      " [15  1 18  1]]\n",
      "> NDCG Score | role | categ  | 0.83237\n",
      "> NDCG Score | role | proba* | 0.85557\n",
      "> NDCG Score | full | categ  | 0.86043\n",
      "> NDCG Score | full | proba* | 0.81832\n",
      "=== INSURER ======\n",
      "Items in training set: 19 (100.00%)\n",
      "Items in eval set: 0\n",
      "Items in test set: 47\n",
      " = 66\n",
      "Number of source documents: 15 total, 8 train, 0 eval 7 test\n",
      "Absolute (training): IR 1.00, N 1.00, R 8.00, HR 9.00\n",
      "Relative (training): IR 0.05, N 0.05, R 0.42, HR 0.47\n",
      "Absolute (eval): IR 0.00, N 0.00, R 0.00, HR 0.00\n",
      "Relative (eval): IR nan, N nan, R nan, HR nan\n",
      "Role samples for INSURER in train: 19, eval: 0, test: 47\n",
      "NDCG after 100x random order:\n",
      " > mean ndcg = nan | std = nan\n",
      "NDCG for worst case (inverted best) order:\n",
      " > ndcg = nan\n",
      "Accuracy | role : 0.340425531915\n",
      "Accuracy | full : 0.0425531914894\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " irrelevant       0.00      0.00      0.00         1\n",
      "    neutral       0.00      0.00      0.00         7\n",
      "   relevant       0.25      0.11      0.15        19\n",
      "     highly       0.00      0.00      0.00        20\n",
      "\n",
      "avg / total       0.10      0.04      0.06        47\n",
      "\n",
      "[[ 0  0  1  0]\n",
      " [ 5  0  2  0]\n",
      " [16  1  2  0]\n",
      " [17  0  3  0]]\n",
      "> NDCG Score | role | categ  | 0.85980\n",
      "> NDCG Score | role | proba* | 0.92090\n",
      "> NDCG Score | full | categ  | 0.86733\n",
      "> NDCG Score | full | proba* | 0.87135\n",
      "=== SERVICER ======\n",
      "Items in training set: 21 (100.00%)\n",
      "Items in eval set: 0\n",
      "Items in test set: 57\n",
      " = 78\n",
      "Number of source documents: 18 total, 8 train, 0 eval 10 test\n",
      "Absolute (training): IR 0.00, N 6.00, R 6.00, HR 9.00\n",
      "Relative (training): IR 0.00, N 0.29, R 0.29, HR 0.43\n",
      "Absolute (eval): IR 0.00, N 0.00, R 0.00, HR 0.00\n",
      "Relative (eval): IR nan, N nan, R nan, HR nan\n",
      "Role samples for SERVICER in train: 21, eval: 0, test: 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tim/Uni/HPI/workspace/FEII/code/feiii_data.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  rating_agg.sum()))\n",
      "/home/tim/Uni/HPI/workspace/FEII/code/feiii_data.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  rating_agg.sum()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG after 100x random order:\n",
      " > mean ndcg = nan | std = nan\n",
      "NDCG for worst case (inverted best) order:\n",
      " > ndcg = nan\n",
      "Accuracy | role : 0.40350877193\n",
      "Accuracy | full : 0.649122807018\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " irrelevant       0.18      1.00      0.30         3\n",
      "    neutral       0.00      0.00      0.00         9\n",
      "   relevant       0.85      0.89      0.87        38\n",
      "     highly       0.00      0.00      0.00         7\n",
      "\n",
      "avg / total       0.58      0.65      0.60        57\n",
      "\n",
      "[[ 3  0  0  0]\n",
      " [ 6  0  3  0]\n",
      " [ 4  0 34  0]\n",
      " [ 4  0  3  0]]\n",
      "> NDCG Score | role | categ  | 0.91002\n",
      "> NDCG Score | role | proba* | 0.85743\n",
      "> NDCG Score | full | categ  | 0.87935\n",
      "> NDCG Score | full | proba* | 0.88095\n",
      "=== TRUSTEE ======\n",
      "Items in training set: 412 (98.10%)\n",
      "Items in eval set: 8\n",
      "Items in test set: 304\n",
      " = 724\n",
      "Number of source documents: 40 total, 19 train, 2 eval 19 test\n",
      "Absolute (training): IR 20.00, N 157.00, R 79.00, HR 156.00\n",
      "Relative (training): IR 0.05, N 0.38, R 0.19, HR 0.38\n",
      "Absolute (eval): IR 1.00, N 7.00, R 0.00, HR 0.00\n",
      "Relative (eval): IR 0.12, N 0.88, R 0.00, HR 0.00\n",
      "Role samples for TRUSTEE in train: 412, eval: 8, test: 304\n",
      "NDCG after 100x random order:\n",
      " > mean ndcg = 0.949114610812 | std = 0.0590106996116\n",
      "NDCG for worst case (inverted best) order:\n",
      " > ndcg = 0.845129304044\n",
      "Accuracy | role : 0.539473684211\n",
      "Accuracy | full : 0.299342105263\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " irrelevant       0.75      0.33      0.46         9\n",
      "    neutral       0.17      0.64      0.27        47\n",
      "   relevant       0.39      0.34      0.36       124\n",
      "     highly       0.80      0.13      0.22       124\n",
      "\n",
      "avg / total       0.53      0.30      0.29       304\n",
      "\n",
      "[[ 3  4  2  0]\n",
      " [ 1 30 14  2]\n",
      " [ 0 80 42  2]\n",
      " [ 0 58 50 16]]\n",
      "> NDCG Score | role | categ  | 0.97365\n",
      "> NDCG Score | role | proba* | 0.97816\n",
      "> NDCG Score | full | categ  | 0.94868\n",
      "> NDCG Score | full | proba* | 0.91789\n",
      "=== ISSUER ======\n",
      "Items in training set: 122 (94.57%)\n",
      "Items in eval set: 7\n",
      "Items in test set: 98\n",
      " = 227\n",
      "Number of source documents: 46 total, 22 train, 2 eval 22 test\n",
      "Absolute (training): IR 30.00, N 42.00, R 30.00, HR 20.00\n",
      "Relative (training): IR 0.25, N 0.34, R 0.25, HR 0.16\n",
      "Absolute (eval): IR 2.00, N 3.00, R 0.00, HR 2.00\n",
      "Relative (eval): IR 0.29, N 0.43, R 0.00, HR 0.29\n",
      "Role samples for ISSUER in train: 122, eval: 7, test: 98\n",
      "NDCG after 100x random order:\n",
      " > mean ndcg = 0.737426379704 | std = 0.115732421393\n",
      "NDCG for worst case (inverted best) order:\n",
      " > ndcg = 0.501320240494\n",
      "Accuracy | role : 0.285714285714\n",
      "Accuracy | full : 0.255102040816\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " irrelevant       0.27      0.76      0.40        21\n",
      "    neutral       0.00      0.00      0.00        27\n",
      "   relevant       0.26      0.33      0.29        27\n",
      "     highly       0.00      0.00      0.00        23\n",
      "\n",
      "avg / total       0.13      0.26      0.17        98\n",
      "\n",
      "[[16  0  5  0]\n",
      " [20  0  7  0]\n",
      " [14  4  9  0]\n",
      " [ 9  0 14  0]]\n",
      "> NDCG Score | role | categ  | 0.84091\n",
      "> NDCG Score | role | proba* | 0.86422\n",
      "> NDCG Score | full | categ  | 0.89855\n",
      "> NDCG Score | full | proba* | 0.80108\n",
      "=== UNDERWRITER ======\n",
      "Items in training set: 14 (66.67%)\n",
      "Items in eval set: 7\n",
      "Items in test set: 40\n",
      " = 61\n",
      "Number of source documents: 16 total, 6 train, 1 eval 9 test\n",
      "Absolute (training): IR 0.00, N 0.00, R 7.00, HR 7.00\n",
      "Relative (training): IR 0.00, N 0.00, R 0.50, HR 0.50\n",
      "Absolute (eval): IR 0.00, N 0.00, R 7.00, HR 0.00\n",
      "Relative (eval): IR 0.00, N 0.00, R 1.00, HR 0.00\n",
      "Role samples for UNDERWRITER in train: 14, eval: 7, test: 40\n",
      "NDCG after 100x random order:\n",
      " > mean ndcg = 1.0 | std = 0.0\n",
      "NDCG for worst case (inverted best) order:\n",
      " > ndcg = 1.0\n",
      "Accuracy | role : 0.575\n",
      "Accuracy | full : 0.175\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " irrelevant       0.08      1.00      0.15         3\n",
      "    neutral       0.00      0.00      0.00         2\n",
      "   relevant       1.00      0.27      0.42        15\n",
      "     highly       0.00      0.00      0.00        20\n",
      "\n",
      "avg / total       0.38      0.17      0.17        40\n",
      "\n",
      "[[ 3  0  0  0]\n",
      " [ 2  0  0  0]\n",
      " [11  0  4  0]\n",
      " [20  0  0  0]]\n",
      "> NDCG Score | role | categ  | 0.98368\n",
      "> NDCG Score | role | proba* | 0.97336\n",
      "> NDCG Score | full | categ  | 0.87827\n",
      "> NDCG Score | full | proba* | 0.87827\n",
      "=== SELLER ======\n",
      "Items in training set: 20 (100.00%)\n",
      "Items in eval set: 0\n",
      "Items in test set: 49\n",
      " = 69\n",
      "Number of source documents: 19 total, 10 train, 0 eval 9 test\n",
      "Absolute (training): IR 0.00, N 1.00, R 14.00, HR 5.00\n",
      "Relative (training): IR 0.00, N 0.05, R 0.70, HR 0.25\n",
      "Absolute (eval): IR 0.00, N 0.00, R 0.00, HR 0.00\n",
      "Relative (eval): IR nan, N nan, R nan, HR nan\n",
      "Role samples for SELLER in train: 20, eval: 0, test: 49\n",
      "NDCG after 100x random order:\n",
      " > mean ndcg = nan | std = nan\n",
      "NDCG for worst case (inverted best) order:\n",
      " > ndcg = nan\n",
      "Accuracy | role : 0.265306122449\n",
      "Accuracy | full : 0.163265306122\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " irrelevant       0.10      0.75      0.18         4\n",
      "    neutral       0.25      0.10      0.14        10\n",
      "   relevant       0.27      0.24      0.25        17\n",
      "     highly       0.00      0.00      0.00        18\n",
      "\n",
      "avg / total       0.15      0.16      0.13        49\n",
      "\n",
      "[[ 3  0  1  0]\n",
      " [ 5  1  4  0]\n",
      " [10  3  4  0]\n",
      " [12  0  6  0]]\n",
      "> NDCG Score | role | categ  | 0.91762\n",
      "> NDCG Score | role | proba* | 0.93379\n",
      "> NDCG Score | full | categ  | 0.81659\n",
      "> NDCG Score | full | proba* | 0.87735\n",
      "=== AFFILIATE ======\n",
      "Items in training set: 161 (86.56%)\n",
      "Items in eval set: 25\n",
      "Items in test set: 129\n",
      " = 315\n",
      "Number of source documents: 41 total, 20 train, 2 eval 19 test\n",
      "Absolute (training): IR 13.00, N 34.00, R 60.00, HR 54.00\n",
      "Relative (training): IR 0.08, N 0.21, R 0.37, HR 0.34\n",
      "Absolute (eval): IR 13.00, N 6.00, R 2.00, HR 4.00\n",
      "Relative (eval): IR 0.52, N 0.24, R 0.08, HR 0.16\n",
      "Role samples for AFFILIATE in train: 161, eval: 25, test: 129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tim/Uni/HPI/workspace/FEII/code/feiii_data.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  rating_agg.sum()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG after 100x random order:\n",
      " > mean ndcg = 0.620020893332 | std = 0.102111032104\n",
      "NDCG for worst case (inverted best) order:\n",
      " > ndcg = 0.390859736659\n",
      "Accuracy | role : 0.325581395349\n",
      "Accuracy | full : 0.201550387597\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " irrelevant       0.07      0.35      0.12        17\n",
      "    neutral       0.00      0.00      0.00        12\n",
      "   relevant       0.43      0.37      0.40        54\n",
      "     highly       0.00      0.00      0.00        46\n",
      "\n",
      "avg / total       0.19      0.20      0.18       129\n",
      "\n",
      "[[ 6  0 11  0]\n",
      " [ 7  0  5  0]\n",
      " [32  2 20  0]\n",
      " [36  0 10  0]]\n",
      "> NDCG Score | role | categ  | 0.87983\n",
      "> NDCG Score | role | proba* | 0.87983\n",
      "> NDCG Score | full | categ  | 0.84975\n",
      "> NDCG Score | full | proba* | 0.89170\n",
      "TOTAL NDCG | role | categ  | 0.97074\n",
      "TOTAL NDCG | role | proba* | 0.95251\n",
      "TOTAL NDCG | full | categ  | 0.94830\n",
      "TOTAL NDCG | full | proba* | 0.93071\n"
     ]
    }
   ],
   "source": [
    "fm, m, res, macro_res, conf_matrix_role, conf_matrix_full = evaluate(data, pipeline, score_func=score_func,predict_on='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leaving 3 docs out per fold\n",
      "\n",
      "\n",
      "==========================================================================\n",
      "===                      CROSSEVAL ITERATION 1/5                     =====\n",
      "==========================================================================\n",
      "\n",
      "\n",
      "Items in training set: 883 (90.56%)\n",
      "Items in eval set: 92\n",
      "Items in test set: 900\n",
      " = 1875\n",
      "Number of source documents: 50 total, 22 train, 3 eval 25 test\n",
      "Absolute (training): IR 87.00, N 292.00, R 221.00, HR 283.00\n",
      "Relative (training): IR 0.10, N 0.33, R 0.25, HR 0.32\n",
      "Absolute (eval): IR 3.00, N 15.00, R 62.00, HR 12.00\n",
      "Relative (eval): IR 0.03, N 0.16, R 0.67, HR 0.13\n",
      "Role samples for GUARANTOR in train: 22, eval: 12, test: 28\n",
      "Role samples for SERVICER in train: 21, eval: 0, test: 57\n",
      "Role samples for AGENT in train: 60, eval: 1, test: 40\n",
      "Role samples for COUNTERPART in train: 61, eval: 3, test: 108\n",
      "Role samples for TRUSTEE in train: 379, eval: 41, test: 304\n",
      "Role samples for ISSUER in train: 117, eval: 12, test: 98\n",
      "Role samples for UNDERWRITER in train: 20, eval: 1, test: 40\n",
      "Role samples for SELLER in train: 17, eval: 3, test: 49\n",
      "Role samples for INSURER in train: 18, eval: 1, test: 47\n",
      "Role samples for AFFILIATE in train: 168, eval: 18, test: 129\n",
      "=== GUARANTOR ======\n",
      "Items in training set: 22 (64.71%)\n",
      "Items in eval set: 12\n",
      "Items in test set: 28\n",
      " = 62\n",
      "Number of source documents: 15 total, 5 train, 1 eval 9 test\n",
      "Absolute (training): IR 1.00, N 3.00, R 18.00, HR 0.00\n",
      "Relative (training): IR 0.05, N 0.14, R 0.82, HR 0.00\n",
      "Absolute (eval): IR 0.00, N 0.00, R 4.00, HR 8.00\n",
      "Relative (eval): IR 0.00, N 0.00, R 0.33, HR 0.67\n",
      "Role samples for GUARANTOR in train: 22, eval: 12, test: 28\n",
      "NDCG after 100x random order:\n",
      " > mean ndcg = 0.955260341628 | std = 0.0259099861368\n",
      "NDCG for worst case (inverted best) order:\n",
      " > ndcg = 0.880462653916\n",
      "Accuracy | role : 0.785714285714\n",
      "Accuracy | full : 0.607142857143\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " irrelevant       0.00      0.00      0.00         0\n",
      "    neutral       0.00      0.00      0.00         3\n",
      "   relevant       0.74      0.77      0.76        22\n",
      "     highly       0.00      0.00      0.00         3\n",
      "\n",
      "avg / total       0.58      0.61      0.59        28\n",
      "\n",
      "[[ 0  0  0  0]\n",
      " [ 0  0  3  0]\n",
      " [ 0  5 17  0]\n",
      " [ 0  0  3  0]]\n",
      "> NDCG Score | role | categ  | 0.84067\n",
      "> NDCG Score | role | proba* | 0.88487\n",
      "> NDCG Score | full | categ  | 0.84053\n",
      "> NDCG Score | full | proba* | 0.85995\n",
      "=== AGENT ======\n",
      "Items in training set: 60 (98.36%)\n",
      "Items in eval set: 1\n",
      "Items in test set: 40\n",
      " = 101\n",
      "Number of source documents: 25 total, 15 train, 1 eval 9 test\n",
      "Absolute (training): IR 3.00, N 34.00, R 18.00, HR 5.00\n",
      "Relative (training): IR 0.05, N 0.57, R 0.30, HR 0.08\n",
      "Absolute (eval): IR 0.00, N 1.00, R 0.00, HR 0.00\n",
      "Relative (eval): IR 0.00, N 1.00, R 0.00, HR 0.00\n",
      "Role samples for AGENT in train: 60, eval: 1, test: 40\n",
      "NDCG after 100x random order:\n",
      " > mean ndcg = 1.0 | std = 0.0\n",
      "NDCG for worst case (inverted best) order:\n",
      " > ndcg = 1.0\n",
      "Accuracy | role : 0.2\n",
      "Accuracy | full : 0.2\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " irrelevant       0.00      0.00      0.00         4\n",
      "    neutral       0.00      0.00      0.00         8\n",
      "   relevant       0.27      0.53      0.36        15\n",
      "     highly       0.00      0.00      0.00        13\n",
      "\n",
      "avg / total       0.10      0.20      0.13        40\n",
      "\n",
      "[[ 0  1  3  0]\n",
      " [ 0  0  8  0]\n",
      " [ 0  4  8  3]\n",
      " [ 0  2 11  0]]\n",
      "> NDCG Score | role | categ  | 0.89290\n",
      "> NDCG Score | role | proba* | 0.86714\n",
      "> NDCG Score | full | categ  | 0.88825\n",
      "> NDCG Score | full | proba* | 0.86365\n",
      "=== COUNTERPART ======\n",
      "Items in training set: 61 (95.31%)\n",
      "Items in eval set: 3\n",
      "Items in test set: 108\n",
      " = 172\n",
      "Number of source documents: 31 total, 15 train, 2 eval 14 test\n",
      "Absolute (training): IR 6.00, N 11.00, R 28.00, HR 16.00\n",
      "Relative (training): IR 0.10, N 0.18, R 0.46, HR 0.26\n",
      "Absolute (eval): IR 0.00, N 1.00, R 2.00, HR 0.00\n",
      "Relative (eval): IR 0.00, N 0.33, R 0.67, HR 0.00\n",
      "Role samples for COUNTERPART in train: 61, eval: 3, test: 108\n",
      "NDCG after 100x random order:\n",
      " > mean ndcg = 0.949791020892 | std = 0.0384779546398\n",
      "NDCG for worst case (inverted best) order:\n",
      " > ndcg = 0.920303207764\n",
      "Accuracy | role : 0.37037037037\n",
      "Accuracy | full : 0.324074074074\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " irrelevant       0.00      0.00      0.00        18\n",
      "    neutral       0.00      0.00      0.00        17\n",
      "   relevant       0.34      0.92      0.50        38\n",
      "     highly       0.00      0.00      0.00        35\n",
      "\n",
      "avg / total       0.12      0.32      0.18       108\n",
      "\n",
      "[[ 0  0 18  0]\n",
      " [ 0  0 17  0]\n",
      " [ 0  3 35  0]\n",
      " [ 0  3 32  0]]\n",
      "> NDCG Score | role | categ  | 0.87294\n",
      "> NDCG Score | role | proba* | 0.88182\n",
      "> NDCG Score | full | categ  | 0.87125\n",
      "> NDCG Score | full | proba* | 0.83547\n",
      "=== INSURER ======\n",
      "Items in training set: 18 (94.74%)\n",
      "Items in eval set: 1\n",
      "Items in test set: 47\n",
      " = 66\n",
      "Number of source documents: 15 total, 7 train, 1 eval 7 test\n",
      "Absolute (training): IR 1.00, N 1.00, R 8.00, HR 8.00\n",
      "Relative (training): IR 0.06, N 0.06, R 0.44, HR 0.44\n",
      "Absolute (eval): IR 0.00, N 0.00, R 0.00, HR 1.00\n",
      "Relative (eval): IR 0.00, N 0.00, R 0.00, HR 1.00\n",
      "Role samples for INSURER in train: 18, eval: 1, test: 47\n",
      "NDCG after 100x random order:\n",
      " > mean ndcg = 1.0 | std = 0.0\n",
      "NDCG for worst case (inverted best) order:\n",
      " > ndcg = 1.0\n",
      "Accuracy | role : 0.425531914894\n",
      "Accuracy | full : 0.382978723404\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " irrelevant       0.00      0.00      0.00         1\n",
      "    neutral       0.00      0.00      0.00         7\n",
      "   relevant       0.40      0.95      0.56        19\n",
      "     highly       0.00      0.00      0.00        20\n",
      "\n",
      "avg / total       0.16      0.38      0.23        47\n",
      "\n",
      "[[ 0  0  1  0]\n",
      " [ 0  0  7  0]\n",
      " [ 0  0 18  1]\n",
      " [ 0  1 19  0]]\n",
      "> NDCG Score | role | categ  | 0.89620\n",
      "> NDCG Score | role | proba* | 0.91633\n",
      "> NDCG Score | full | categ  | 0.89690\n",
      "> NDCG Score | full | proba* | 0.88762\n",
      "=== SERVICER ======\n",
      "Items in training set: 21 (100.00%)\n",
      "Items in eval set: 0\n",
      "Items in test set: 57\n",
      " = 78\n",
      "Number of source documents: 18 total, 8 train, 0 eval 10 test\n",
      "Absolute (training): IR 0.00, N 6.00, R 6.00, HR 9.00\n",
      "Relative (training): IR 0.00, N 0.29, R 0.29, HR 0.43\n",
      "Absolute (eval): IR 0.00, N 0.00, R 0.00, HR 0.00\n",
      "Relative (eval): IR nan, N nan, R nan, HR nan\n",
      "Role samples for SERVICER in train: 21, eval: 0, test: 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tim/Uni/HPI/workspace/FEII/code/feiii_data.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  rating_agg.sum()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG after 100x random order:\n",
      " > mean ndcg = nan | std = nan\n",
      "NDCG for worst case (inverted best) order:\n",
      " > ndcg = nan\n",
      "Accuracy | role : 0.122807017544\n",
      "Accuracy | full : 0.684210526316\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " irrelevant       0.00      0.00      0.00         3\n",
      "    neutral       0.00      0.00      0.00         9\n",
      "   relevant       0.68      1.00      0.81        38\n",
      "     highly       1.00      0.14      0.25         7\n",
      "\n",
      "avg / total       0.58      0.68      0.57        57\n",
      "\n",
      "[[ 0  0  3  0]\n",
      " [ 0  0  9  0]\n",
      " [ 0  0 38  0]\n",
      " [ 0  0  6  1]]\n",
      "> NDCG Score | role | categ  | 0.85663\n",
      "> NDCG Score | role | proba* | 0.87166\n",
      "> NDCG Score | full | categ  | 0.88344\n",
      "> NDCG Score | full | proba* | 0.85753\n",
      "=== TRUSTEE ======\n",
      "Items in training set: 379 (90.24%)\n",
      "Items in eval set: 41\n",
      "Items in test set: 304\n",
      " = 724\n",
      "Number of source documents: 40 total, 18 train, 3 eval 19 test\n",
      "Absolute (training): IR 21.00, N 161.00, R 41.00, HR 156.00\n",
      "Relative (training): IR 0.06, N 0.42, R 0.11, HR 0.41\n",
      "Absolute (eval): IR 0.00, N 3.00, R 38.00, HR 0.00\n",
      "Relative (eval): IR 0.00, N 0.07, R 0.93, HR 0.00\n",
      "Role samples for TRUSTEE in train: 379, eval: 41, test: 304\n",
      "NDCG after 100x random order:\n",
      " > mean ndcg = 0.986169550965 | std = 0.0119911805726\n",
      "NDCG for worst case (inverted best) order:\n",
      " > ndcg = 0.912475740672\n",
      "Accuracy | role : 0.480263157895\n",
      "Accuracy | full : 0.351973684211\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " irrelevant       0.00      0.00      0.00         9\n",
      "    neutral       0.12      0.28      0.16        47\n",
      "   relevant       0.00      0.00      0.00       124\n",
      "     highly       0.50      0.76      0.60       124\n",
      "\n",
      "avg / total       0.22      0.35      0.27       304\n",
      "\n",
      "[[ 0  5  3  1]\n",
      " [ 0 13  1 33]\n",
      " [ 0 65  0 59]\n",
      " [ 0 30  0 94]]\n",
      "> NDCG Score | role | categ  | 0.97365\n",
      "> NDCG Score | role | proba* | 0.95596\n",
      "> NDCG Score | full | categ  | 0.96839\n",
      "> NDCG Score | full | proba* | 0.96231\n",
      "=== ISSUER ======\n",
      "Items in training set: 117 (90.70%)\n",
      "Items in eval set: 12\n",
      "Items in test set: 98\n",
      " = 227\n",
      "Number of source documents: 46 total, 21 train, 3 eval 22 test\n",
      "Absolute (training): IR 29.00, N 39.00, R 28.00, HR 21.00\n",
      "Relative (training): IR 0.25, N 0.33, R 0.24, HR 0.18\n",
      "Absolute (eval): IR 3.00, N 6.00, R 2.00, HR 1.00\n",
      "Relative (eval): IR 0.25, N 0.50, R 0.17, HR 0.08\n",
      "Role samples for ISSUER in train: 117, eval: 12, test: 98\n",
      "NDCG after 100x random order:\n",
      " > mean ndcg = 0.727580457342 | std = 0.0840833733442\n",
      "NDCG for worst case (inverted best) order:\n",
      " > ndcg = 0.50551653467\n",
      "Accuracy | role : 0.285714285714\n",
      "Accuracy | full : 0.234693877551\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " irrelevant       0.00      0.00      0.00        21\n",
      "    neutral       0.12      0.04      0.06        27\n",
      "   relevant       0.24      0.81      0.38        27\n",
      "     highly       0.00      0.00      0.00        23\n",
      "\n",
      "avg / total       0.10      0.23      0.12        98\n",
      "\n",
      "[[ 0  0 21  0]\n",
      " [ 0  1 26  0]\n",
      " [ 0  5 22  0]\n",
      " [ 0  2 21  0]]\n",
      "> NDCG Score | role | categ  | 0.90284\n",
      "> NDCG Score | role | proba* | 0.90935\n",
      "> NDCG Score | full | categ  | 0.70250\n",
      "> NDCG Score | full | proba* | 0.72075\n",
      "=== UNDERWRITER ======\n",
      "Items in training set: 20 (95.24%)\n",
      "Items in eval set: 1\n",
      "Items in test set: 40\n",
      " = 61\n",
      "Number of source documents: 16 total, 6 train, 1 eval 9 test\n",
      "Absolute (training): IR 0.00, N 0.00, R 14.00, HR 6.00\n",
      "Relative (training): IR 0.00, N 0.00, R 0.70, HR 0.30\n",
      "Absolute (eval): IR 0.00, N 0.00, R 0.00, HR 1.00\n",
      "Relative (eval): IR 0.00, N 0.00, R 0.00, HR 1.00\n",
      "Role samples for UNDERWRITER in train: 20, eval: 1, test: 40\n",
      "NDCG after 100x random order:\n",
      " > mean ndcg = 1.0 | std = 0.0\n",
      "NDCG for worst case (inverted best) order:\n",
      " > ndcg = 1.0\n",
      "Accuracy | role : 0.375\n",
      "Accuracy | full : 0.275\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " irrelevant       0.00      0.00      0.00         3\n",
      "    neutral       0.11      1.00      0.19         2\n",
      "   relevant       0.43      0.60      0.50        15\n",
      "     highly       0.00      0.00      0.00        20\n",
      "\n",
      "avg / total       0.17      0.28      0.20        40\n",
      "\n",
      "[[ 0  1  2  0]\n",
      " [ 0  2  0  0]\n",
      " [ 0  6  9  0]\n",
      " [ 0 10 10  0]]\n",
      "> NDCG Score | role | categ  | 0.86908\n",
      "> NDCG Score | role | proba* | 0.96520\n",
      "> NDCG Score | full | categ  | 0.86842\n",
      "> NDCG Score | full | proba* | 0.87527\n",
      "=== SELLER ======\n",
      "Items in training set: 17 (85.00%)\n",
      "Items in eval set: 3\n",
      "Items in test set: 49\n",
      " = 69\n",
      "Number of source documents: 19 total, 8 train, 2 eval 9 test\n",
      "Absolute (training): IR 0.00, N 1.00, R 11.00, HR 5.00\n",
      "Relative (training): IR 0.00, N 0.06, R 0.65, HR 0.29\n",
      "Absolute (eval): IR 0.00, N 0.00, R 3.00, HR 0.00\n",
      "Relative (eval): IR 0.00, N 0.00, R 1.00, HR 0.00\n",
      "Role samples for SELLER in train: 17, eval: 3, test: 49\n",
      "NDCG after 100x random order:\n",
      " > mean ndcg = 1.0 | std = 0.0\n",
      "NDCG for worst case (inverted best) order:\n",
      " > ndcg = 1.0\n",
      "Accuracy | role : 0.34693877551\n",
      "Accuracy | full : 0.387755102041\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " irrelevant       0.00      0.00      0.00         4\n",
      "    neutral       0.17      0.10      0.12        10\n",
      "   relevant       0.33      0.71      0.45        17\n",
      "     highly       0.86      0.33      0.48        18\n",
      "\n",
      "avg / total       0.46      0.39      0.36        49\n",
      "\n",
      "[[ 0  0  4  0]\n",
      " [ 0  1  9  0]\n",
      " [ 0  4 12  1]\n",
      " [ 0  1 11  6]]\n",
      "> NDCG Score | role | categ  | 0.80424\n",
      "> NDCG Score | role | proba* | 0.82279\n",
      "> NDCG Score | full | categ  | 0.95344\n",
      "> NDCG Score | full | proba* | 0.91376\n",
      "=== AFFILIATE ======\n",
      "Items in training set: 168 (90.32%)\n",
      "Items in eval set: 18\n",
      "Items in test set: 129\n",
      " = 315\n",
      "Number of source documents: 41 total, 20 train, 2 eval 19 test\n",
      "Absolute (training): IR 26.00, N 36.00, R 49.00, HR 57.00\n",
      "Relative (training): IR 0.15, N 0.21, R 0.29, HR 0.34\n",
      "Absolute (eval): IR 0.00, N 4.00, R 13.00, HR 1.00\n",
      "Relative (eval): IR 0.00, N 0.22, R 0.72, HR 0.06\n",
      "Role samples for AFFILIATE in train: 168, eval: 18, test: 129\n",
      "NDCG after 100x random order:\n",
      " > mean ndcg = 0.914360162424 | std = 0.0302904278897\n",
      "NDCG for worst case (inverted best) order:\n",
      " > ndcg = 0.802689844355\n",
      "Accuracy | role : 0.441860465116\n",
      "Accuracy | full : 0.403100775194\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " irrelevant       0.00      0.00      0.00        17\n",
      "    neutral       0.00      0.00      0.00        12\n",
      "   relevant       0.49      0.89      0.63        54\n",
      "     highly       1.00      0.09      0.16        46\n",
      "\n",
      "avg / total       0.56      0.40      0.32       129\n",
      "\n",
      "[[ 0  0 17  0]\n",
      " [ 0  0 12  0]\n",
      " [ 0  6 48  0]\n",
      " [ 0 21 21  4]]\n",
      "> NDCG Score | role | categ  | 0.88583\n",
      "> NDCG Score | role | proba* | 0.95557\n",
      "> NDCG Score | full | categ  | 0.90834\n",
      "> NDCG Score | full | proba* | 0.94236\n",
      "TOTAL NDCG | role | categ  | 0.97068\n",
      "TOTAL NDCG | role | proba* | 0.95234\n",
      "TOTAL NDCG | full | categ  | 0.92662\n",
      "TOTAL NDCG | full | proba* | 0.92787\n",
      "baseline_rand 10\n",
      "baseline_worst 10\n",
      "ndcg_role 10\n",
      "ndcg_full 10\n",
      "ndcg_role_proba 10\n",
      "ndcg_full_proba 10\n",
      "acc_role 10\n",
      "acc_full 10\n",
      "f1_role 10\n",
      "f1_full 10\n",
      "\n",
      "\n",
      "==========================================================================\n",
      "===                      CROSSEVAL ITERATION 2/5                     =====\n",
      "==========================================================================\n",
      "\n",
      "\n",
      "Items in training set: 920 (94.36%)\n",
      "Items in eval set: 55\n",
      "Items in test set: 900\n",
      " = 1875\n",
      "Number of source documents: 50 total, 22 train, 3 eval 25 test\n",
      "Absolute (training): IR 78.00, N 296.00, R 265.00, HR 281.00\n",
      "Relative (training): IR 0.08, N 0.32, R 0.29, HR 0.31\n",
      "Absolute (eval): IR 12.00, N 11.00, R 18.00, HR 14.00\n",
      "Relative (eval): IR 0.22, N 0.20, R 0.33, HR 0.25\n",
      "Role samples for GUARANTOR in train: 34, eval: 0, test: 28\n",
      "Role samples for SERVICER in train: 21, eval: 0, test: 57\n",
      "Role samples for AGENT in train: 51, eval: 10, test: 40\n",
      "Role samples for COUNTERPART in train: 57, eval: 7, test: 108\n",
      "Role samples for TRUSTEE in train: 417, eval: 3, test: 304\n",
      "Role samples for ISSUER in train: 115, eval: 14, test: 98\n",
      "Role samples for UNDERWRITER in train: 21, eval: 0, test: 40\n",
      "Role samples for SELLER in train: 20, eval: 0, test: 49\n",
      "Role samples for INSURER in train: 19, eval: 0, test: 47\n",
      "Role samples for AFFILIATE in train: 165, eval: 21, test: 129\n",
      "=== GUARANTOR ======\n",
      "Items in training set: 34 (100.00%)\n",
      "Items in eval set: 0\n",
      "Items in test set: 28\n",
      " = 62\n",
      "Number of source documents: 15 total, 6 train, 0 eval 9 test\n",
      "Absolute (training): IR 1.00, N 3.00, R 22.00, HR 8.00\n",
      "Relative (training): IR 0.03, N 0.09, R 0.65, HR 0.24\n",
      "Absolute (eval): IR 0.00, N 0.00, R 0.00, HR 0.00\n",
      "Relative (eval): IR nan, N nan, R nan, HR nan\n",
      "Role samples for GUARANTOR in train: 34, eval: 0, test: 28\n",
      "NDCG after 100x random order:\n",
      " > mean ndcg = nan | std = nan\n",
      "NDCG for worst case (inverted best) order:\n",
      " > ndcg = nan\n",
      "Accuracy | role : 0.785714285714\n",
      "Accuracy | full : 0.607142857143\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " irrelevant       0.00      0.00      0.00         0\n",
      "    neutral       0.00      0.00      0.00         3\n",
      "   relevant       0.74      0.77      0.76        22\n",
      "     highly       0.00      0.00      0.00         3\n",
      "\n",
      "avg / total       0.58      0.61      0.59        28\n",
      "\n",
      "[[ 0  0  0  0]\n",
      " [ 0  0  3  0]\n",
      " [ 0  5 17  0]\n",
      " [ 0  0  3  0]]\n",
      "> NDCG Score | role | categ  | 0.84067\n",
      "> NDCG Score | role | proba* | 0.89775\n",
      "> NDCG Score | full | categ  | 0.84053\n",
      "> NDCG Score | full | proba* | 0.85995\n",
      "=== AGENT ======\n",
      "Items in training set: 51 (83.61%)\n",
      "Items in eval set: 10\n",
      "Items in test set: 40\n",
      " = 101\n",
      "Number of source documents: 25 total, 13 train, 3 eval 9 test\n",
      "Absolute (training): IR 2.00, N 33.00, R 14.00, HR 2.00\n",
      "Relative (training): IR 0.04, N 0.65, R 0.27, HR 0.04\n",
      "Absolute (eval): IR 1.00, N 2.00, R 4.00, HR 3.00\n",
      "Relative (eval): IR 0.10, N 0.20, R 0.40, HR 0.30\n",
      "Role samples for AGENT in train: 51, eval: 10, test: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tim/Uni/HPI/workspace/FEII/code/feiii_data.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  rating_agg.sum()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG after 100x random order:\n",
      " > mean ndcg = 0.839561048753 | std = 0.0589751809864\n",
      "NDCG for worst case (inverted best) order:\n",
      " > ndcg = 0.65841093381\n",
      "Accuracy | role : 0.2\n",
      "Accuracy | full : 0.2\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " irrelevant       0.00      0.00      0.00         4\n",
      "    neutral       0.00      0.00      0.00         8\n",
      "   relevant       0.27      0.53      0.36        15\n",
      "     highly       0.00      0.00      0.00        13\n",
      "\n",
      "avg / total       0.10      0.20      0.13        40\n",
      "\n",
      "[[ 0  1  3  0]\n",
      " [ 0  0  8  0]\n",
      " [ 0  4  8  3]\n",
      " [ 0  2 11  0]]\n",
      "> NDCG Score | role | categ  | 0.89290\n",
      "> NDCG Score | role | proba* | 0.85306\n",
      "> NDCG Score | full | categ  | 0.88825\n",
      "> NDCG Score | full | proba* | 0.86365\n",
      "=== COUNTERPART ======\n",
      "Items in training set: 57 (89.06%)\n",
      "Items in eval set: 7\n",
      "Items in test set: 108\n",
      " = 172\n",
      "Number of source documents: 31 total, 16 train, 1 eval 14 test\n",
      "Absolute (training): IR 6.00, N 12.00, R 24.00, HR 15.00\n",
      "Relative (training): IR 0.11, N 0.21, R 0.42, HR 0.26\n",
      "Absolute (eval): IR 0.00, N 0.00, R 6.00, HR 1.00\n",
      "Relative (eval): IR 0.00, N 0.00, R 0.86, HR 0.14\n",
      "Role samples for COUNTERPART in train: 57, eval: 7, test: 108\n",
      "NDCG after 100x random order:\n",
      " > mean ndcg = 0.963038548292 | std = 0.026816902481\n",
      "NDCG for worst case (inverted best) order:\n",
      " > ndcg = 0.933003379226\n",
      "Accuracy | role : 0.351851851852\n",
      "Accuracy | full : 0.333333333333\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " irrelevant       0.00      0.00      0.00        18\n",
      "    neutral       0.00      0.00      0.00        17\n",
      "   relevant       0.34      0.92      0.50        38\n",
      "     highly       1.00      0.03      0.06        35\n",
      "\n",
      "avg / total       0.44      0.33      0.19       108\n",
      "\n",
      "[[ 0  0 18  0]\n",
      " [ 0  0 17  0]\n",
      " [ 0  3 35  0]\n",
      " [ 0  2 32  1]]\n",
      "> NDCG Score | role | categ  | 0.87404\n",
      "> NDCG Score | role | proba* | 0.89671\n",
      "> NDCG Score | full | categ  | 0.88605\n",
      "> NDCG Score | full | proba* | 0.86022\n",
      "=== INSURER ======\n",
      "Items in training set: 19 (100.00%)\n",
      "Items in eval set: 0\n",
      "Items in test set: 47\n",
      " = 66\n",
      "Number of source documents: 15 total, 8 train, 0 eval 7 test\n",
      "Absolute (training): IR 1.00, N 1.00, R 8.00, HR 9.00\n",
      "Relative (training): IR 0.05, N 0.05, R 0.42, HR 0.47\n",
      "Absolute (eval): IR 0.00, N 0.00, R 0.00, HR 0.00\n",
      "Relative (eval): IR nan, N nan, R nan, HR nan\n",
      "Role samples for INSURER in train: 19, eval: 0, test: 47\n",
      "NDCG after 100x random order:\n",
      " > mean ndcg = nan | std = nan\n",
      "NDCG for worst case (inverted best) order:\n",
      " > ndcg = nan\n",
      "Accuracy | role : 0.404255319149\n",
      "Accuracy | full : 0.382978723404\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " irrelevant       0.00      0.00      0.00         1\n",
      "    neutral       0.00      0.00      0.00         7\n",
      "   relevant       0.40      0.95      0.56        19\n",
      "     highly       0.00      0.00      0.00        20\n",
      "\n",
      "avg / total       0.16      0.38      0.23        47\n",
      "\n",
      "[[ 0  0  1  0]\n",
      " [ 0  0  7  0]\n",
      " [ 0  0 18  1]\n",
      " [ 0  1 19  0]]\n",
      "> NDCG Score | role | categ  | 0.89620\n",
      "> NDCG Score | role | proba* | 0.88954\n",
      "> NDCG Score | full | categ  | 0.89690\n",
      "> NDCG Score | full | proba* | 0.88742\n",
      "=== SERVICER ======\n",
      "Items in training set: 21 (100.00%)\n",
      "Items in eval set: 0\n",
      "Items in test set: 57\n",
      " = 78\n",
      "Number of source documents: 18 total, 8 train, 0 eval 10 test\n",
      "Absolute (training): IR 0.00, N 6.00, R 6.00, HR 9.00\n",
      "Relative (training): IR 0.00, N 0.29, R 0.29, HR 0.43\n",
      "Absolute (eval): IR 0.00, N 0.00, R 0.00, HR 0.00\n",
      "Relative (eval): IR nan, N nan, R nan, HR nan\n",
      "Role samples for SERVICER in train: 21, eval: 0, test: 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tim/Uni/HPI/workspace/FEII/code/feiii_data.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  rating_agg.sum()))\n",
      "/home/tim/Uni/HPI/workspace/FEII/code/feiii_data.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  rating_agg.sum()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG after 100x random order:\n",
      " > mean ndcg = nan | std = nan\n",
      "NDCG for worst case (inverted best) order:\n",
      " > ndcg = nan\n",
      "Accuracy | role : 0.122807017544\n",
      "Accuracy | full : 0.666666666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " irrelevant       0.00      0.00      0.00         3\n",
      "    neutral       0.00      0.00      0.00         9\n",
      "   relevant       0.68      1.00      0.81        38\n",
      "     highly       0.00      0.00      0.00         7\n",
      "\n",
      "avg / total       0.45      0.67      0.54        57\n",
      "\n",
      "[[ 0  0  3  0]\n",
      " [ 0  0  9  0]\n",
      " [ 0  0 38  0]\n",
      " [ 0  1  6  0]]\n",
      "> NDCG Score | role | categ  | 0.85663\n",
      "> NDCG Score | role | proba* | 0.87166\n",
      "> NDCG Score | full | categ  | 0.85504\n",
      "> NDCG Score | full | proba* | 0.84717\n",
      "=== TRUSTEE ======\n",
      "Items in training set: 417 (99.29%)\n",
      "Items in eval set: 3\n",
      "Items in test set: 304\n",
      " = 724\n",
      "Number of source documents: 40 total, 20 train, 1 eval 19 test\n",
      "Absolute (training): IR 21.00, N 161.00, R 79.00, HR 156.00\n",
      "Relative (training): IR 0.05, N 0.39, R 0.19, HR 0.37\n",
      "Absolute (eval): IR 0.00, N 3.00, R 0.00, HR 0.00\n",
      "Relative (eval): IR 0.00, N 1.00, R 0.00, HR 0.00\n",
      "Role samples for TRUSTEE in train: 417, eval: 3, test: 304\n",
      "NDCG after 100x random order:\n",
      " > mean ndcg = 1.0 | std = 0.0\n",
      "NDCG for worst case (inverted best) order:\n",
      " > ndcg = 1.0\n",
      "Accuracy | role : 0.496710526316\n",
      "Accuracy | full : 0.351973684211\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " irrelevant       0.00      0.00      0.00         9\n",
      "    neutral       0.12      0.28      0.16        47\n",
      "   relevant       0.00      0.00      0.00       124\n",
      "     highly       0.50      0.76      0.60       124\n",
      "\n",
      "avg / total       0.22      0.35      0.27       304\n",
      "\n",
      "[[ 0  5  3  1]\n",
      " [ 0 13  1 33]\n",
      " [ 0 65  0 59]\n",
      " [ 0 30  0 94]]\n",
      "> NDCG Score | role | categ  | 0.97332\n",
      "> NDCG Score | role | proba* | 0.98007\n",
      "> NDCG Score | full | categ  | 0.96839\n",
      "> NDCG Score | full | proba* | 0.95937\n",
      "=== ISSUER ======\n",
      "Items in training set: 115 (89.15%)\n",
      "Items in eval set: 14\n",
      "Items in test set: 98\n",
      " = 227\n",
      "Number of source documents: 46 total, 21 train, 3 eval 22 test\n",
      "Absolute (training): IR 24.00, N 43.00, R 30.00, HR 18.00\n",
      "Relative (training): IR 0.21, N 0.37, R 0.26, HR 0.16\n",
      "Absolute (eval): IR 8.00, N 2.00, R 0.00, HR 4.00\n",
      "Relative (eval): IR 0.57, N 0.14, R 0.00, HR 0.29\n",
      "Role samples for ISSUER in train: 115, eval: 14, test: 98\n",
      "NDCG after 100x random order:\n",
      " > mean ndcg = 0.612470814982 | std = 0.116894974402\n",
      "NDCG for worst case (inverted best) order:\n",
      " > ndcg = 0.383845147277\n",
      "Accuracy | role : 0.295918367347\n",
      "Accuracy | full : 0.234693877551\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " irrelevant       0.00      0.00      0.00        21\n",
      "    neutral       0.12      0.04      0.06        27\n",
      "   relevant       0.24      0.81      0.38        27\n",
      "     highly       0.00      0.00      0.00        23\n",
      "\n",
      "avg / total       0.10      0.23      0.12        98\n",
      "\n",
      "[[ 0  0 21  0]\n",
      " [ 0  1 26  0]\n",
      " [ 0  5 22  0]\n",
      " [ 0  2 21  0]]\n",
      "> NDCG Score | role | categ  | 0.89287\n",
      "> NDCG Score | role | proba* | 0.90213\n",
      "> NDCG Score | full | categ  | 0.70250\n",
      "> NDCG Score | full | proba* | 0.72256\n",
      "=== UNDERWRITER ======\n",
      "Items in training set: 21 (100.00%)\n",
      "Items in eval set: 0\n",
      "Items in test set: 40\n",
      " = 61\n",
      "Number of source documents: 16 total, 7 train, 0 eval 9 test\n",
      "Absolute (training): IR 0.00, N 0.00, R 14.00, HR 7.00\n",
      "Relative (training): IR 0.00, N 0.00, R 0.67, HR 0.33\n",
      "Absolute (eval): IR 0.00, N 0.00, R 0.00, HR 0.00\n",
      "Relative (eval): IR nan, N nan, R nan, HR nan\n",
      "Role samples for UNDERWRITER in train: 21, eval: 0, test: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tim/Uni/HPI/workspace/FEII/code/feiii_data.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  rating_agg.sum()))\n",
      "/home/tim/Uni/HPI/workspace/FEII/code/feiii_data.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  rating_agg.sum()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG after 100x random order:\n",
      " > mean ndcg = nan | std = nan\n",
      "NDCG for worst case (inverted best) order:\n",
      " > ndcg = nan\n",
      "Accuracy | role : 0.375\n",
      "Accuracy | full : 0.275\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " irrelevant       0.00      0.00      0.00         3\n",
      "    neutral       0.11      1.00      0.19         2\n",
      "   relevant       0.43      0.60      0.50        15\n",
      "     highly       0.00      0.00      0.00        20\n",
      "\n",
      "avg / total       0.17      0.28      0.20        40\n",
      "\n",
      "[[ 0  1  2  0]\n",
      " [ 0  2  0  0]\n",
      " [ 0  6  9  0]\n",
      " [ 0 10 10  0]]\n",
      "> NDCG Score | role | categ  | 0.86908\n",
      "> NDCG Score | role | proba* | 0.96398\n",
      "> NDCG Score | full | categ  | 0.86842\n",
      "> NDCG Score | full | proba* | 0.87527\n",
      "=== SELLER ======\n",
      "Items in training set: 20 (100.00%)\n",
      "Items in eval set: 0\n",
      "Items in test set: 49\n",
      " = 69\n",
      "Number of source documents: 19 total, 10 train, 0 eval 9 test\n",
      "Absolute (training): IR 0.00, N 1.00, R 14.00, HR 5.00\n",
      "Relative (training): IR 0.00, N 0.05, R 0.70, HR 0.25\n",
      "Absolute (eval): IR 0.00, N 0.00, R 0.00, HR 0.00\n",
      "Relative (eval): IR nan, N nan, R nan, HR nan\n",
      "Role samples for SELLER in train: 20, eval: 0, test: 49\n",
      "NDCG after 100x random order:\n",
      " > mean ndcg = nan | std = nan\n",
      "NDCG for worst case (inverted best) order:\n",
      " > ndcg = nan\n",
      "Accuracy | role : 0.34693877551\n",
      "Accuracy | full : 0.265306122449\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " irrelevant       0.00      0.00      0.00         4\n",
      "    neutral       0.08      0.10      0.09        10\n",
      "   relevant       0.33      0.71      0.45        17\n",
      "     highly       0.00      0.00      0.00        18\n",
      "\n",
      "avg / total       0.13      0.27      0.17        49\n",
      "\n",
      "[[ 0  0  4  0]\n",
      " [ 0  1  9  0]\n",
      " [ 0  5 12  0]\n",
      " [ 0  7 11  0]]\n",
      "> NDCG Score | role | categ  | 0.80424\n",
      "> NDCG Score | role | proba* | 0.86926\n",
      "> NDCG Score | full | categ  | 0.87033\n",
      "> NDCG Score | full | proba* | 0.85053\n",
      "=== AFFILIATE ======\n",
      "Items in training set: 165 (88.71%)\n",
      "Items in eval set: 21\n",
      "Items in test set: 129\n",
      " = 315\n",
      "Number of source documents: 41 total, 19 train, 3 eval 19 test\n",
      "Absolute (training): IR 23.00, N 36.00, R 54.00, HR 52.00\n",
      "Relative (training): IR 0.14, N 0.22, R 0.33, HR 0.32\n",
      "Absolute (eval): IR 3.00, N 4.00, R 8.00, HR 6.00\n",
      "Relative (eval): IR 0.14, N 0.19, R 0.38, HR 0.29\n",
      "Role samples for AFFILIATE in train: 165, eval: 21, test: 129\n",
      "NDCG after 100x random order:\n",
      " > mean ndcg = 0.816913409142 | std = 0.0627895729653\n",
      "NDCG for worst case (inverted best) order:\n",
      " > ndcg = 0.599097151391\n",
      "Accuracy | role : 0.550387596899\n",
      "Accuracy | full : 0.372093023256\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " irrelevant       0.00      0.00      0.00        17\n",
      "    neutral       0.00      0.00      0.00        12\n",
      "   relevant       0.49      0.89      0.63        54\n",
      "     highly       0.00      0.00      0.00        46\n",
      "\n",
      "avg / total       0.21      0.37      0.26       129\n",
      "\n",
      "[[ 0  0 17  0]\n",
      " [ 0  0 12  0]\n",
      " [ 0  6 48  0]\n",
      " [ 0 25 21  0]]\n",
      "> NDCG Score | role | categ  | 0.90583\n",
      "> NDCG Score | role | proba* | 0.92745\n",
      "> NDCG Score | full | categ  | 0.84234\n",
      "> NDCG Score | full | proba* | 0.90322\n",
      "TOTAL NDCG | role | categ  | 0.94288\n",
      "TOTAL NDCG | role | proba* | 0.95365\n",
      "TOTAL NDCG | full | categ  | 0.94697\n",
      "TOTAL NDCG | full | proba* | 0.93915\n",
      "baseline_rand 10\n",
      "baseline_worst 10\n",
      "ndcg_role 10\n",
      "ndcg_full 10\n",
      "ndcg_role_proba 10\n",
      "ndcg_full_proba 10\n",
      "acc_role 10\n",
      "acc_full 10\n",
      "f1_role 10\n",
      "f1_full 10\n",
      "\n",
      "\n",
      "==========================================================================\n",
      "===                      CROSSEVAL ITERATION 3/5                     =====\n",
      "==========================================================================\n",
      "\n",
      "\n",
      "Items in training set: 780 (80.00%)\n",
      "Items in eval set: 195\n",
      "Items in test set: 900\n",
      " = 1875\n",
      "Number of source documents: 50 total, 22 train, 3 eval 25 test\n",
      "Absolute (training): IR 70.00, N 297.00, R 262.00, HR 151.00\n",
      "Relative (training): IR 0.09, N 0.38, R 0.34, HR 0.19\n",
      "Absolute (eval): IR 20.00, N 10.00, R 21.00, HR 144.00\n",
      "Relative (eval): IR 0.10, N 0.05, R 0.11, HR 0.74\n",
      "Role samples for GUARANTOR in train: 34, eval: 0, test: 28\n",
      "Role samples for SERVICER in train: 11, eval: 10, test: 57\n",
      "Role samples for AGENT in train: 58, eval: 3, test: 40\n",
      "Role samples for COUNTERPART in train: 52, eval: 12, test: 108\n",
      "Role samples for TRUSTEE in train: 322, eval: 98, test: 304\n",
      "Role samples for ISSUER in train: 119, eval: 10, test: 98\n",
      "Role samples for UNDERWRITER in train: 17, eval: 4, test: 40\n",
      "Role samples for SELLER in train: 16, eval: 4, test: 49\n",
      "Role samples for INSURER in train: 6, eval: 13, test: 47\n",
      "Role samples for AFFILIATE in train: 145, eval: 41, test: 129\n",
      "=== GUARANTOR ======\n",
      "Items in training set: 34 (100.00%)\n",
      "Items in eval set: 0\n",
      "Items in test set: 28\n",
      " = 62\n",
      "Number of source documents: 15 total, 6 train, 0 eval 9 test\n",
      "Absolute (training): IR 1.00, N 3.00, R 22.00, HR 8.00\n",
      "Relative (training): IR 0.03, N 0.09, R 0.65, HR 0.24\n",
      "Absolute (eval): IR 0.00, N 0.00, R 0.00, HR 0.00\n",
      "Relative (eval): IR nan, N nan, R nan, HR nan\n",
      "Role samples for GUARANTOR in train: 34, eval: 0, test: 28\n",
      "NDCG after 100x random order:\n",
      " > mean ndcg = nan | std = nan\n",
      "NDCG for worst case (inverted best) order:\n",
      " > ndcg = nan\n",
      "Accuracy | role : 0.785714285714\n",
      "Accuracy | full : 0.357142857143\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " irrelevant       0.00      0.00      0.00         0\n",
      "    neutral       0.00      0.00      0.00         3\n",
      "   relevant       0.71      0.45      0.56        22\n",
      "     highly       0.00      0.00      0.00         3\n",
      "\n",
      "avg / total       0.56      0.36      0.44        28\n",
      "\n",
      "[[ 0  0  0  0]\n",
      " [ 0  0  3  0]\n",
      " [ 0 11 10  1]\n",
      " [ 0  2  1  0]]\n",
      "> NDCG Score | role | categ  | 0.84067\n",
      "> NDCG Score | role | proba* | 0.89775\n",
      "> NDCG Score | full | categ  | 0.84963\n",
      "> NDCG Score | full | proba* | 0.88394\n",
      "=== AGENT ======\n",
      "Items in training set: 58 (95.08%)\n",
      "Items in eval set: 3\n",
      "Items in test set: 40\n",
      " = 101\n",
      "Number of source documents: 25 total, 15 train, 1 eval 9 test\n",
      "Absolute (training): IR 3.00, N 34.00, R 16.00, HR 5.00\n",
      "Relative (training): IR 0.05, N 0.59, R 0.28, HR 0.09\n",
      "Absolute (eval): IR 0.00, N 1.00, R 2.00, HR 0.00\n",
      "Relative (eval): IR 0.00, N 0.33, R 0.67, HR 0.00\n",
      "Role samples for AGENT in train: 58, eval: 3, test: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tim/Uni/HPI/workspace/FEII/code/feiii_data.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  rating_agg.sum()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG after 100x random order:\n",
      " > mean ndcg = 0.938633469979 | std = 0.033539000976\n",
      "NDCG for worst case (inverted best) order:\n",
      " > ndcg = 0.920303207764\n",
      "Accuracy | role : 0.2\n",
      "Accuracy | full : 0.325\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " irrelevant       0.00      0.00      0.00         4\n",
      "    neutral       0.00      0.00      0.00         8\n",
      "   relevant       0.37      0.87      0.52        15\n",
      "     highly       0.00      0.00      0.00        13\n",
      "\n",
      "avg / total       0.14      0.33      0.20        40\n",
      "\n",
      "[[ 0  1  3  0]\n",
      " [ 0  0  6  2]\n",
      " [ 0  1 13  1]\n",
      " [ 0  0 13  0]]\n",
      "> NDCG Score | role | categ  | 0.89290\n",
      "> NDCG Score | role | proba* | 0.85633\n",
      "> NDCG Score | full | categ  | 0.84687\n",
      "> NDCG Score | full | proba* | 0.79652\n",
      "=== COUNTERPART ======\n",
      "Items in training set: 52 (81.25%)\n",
      "Items in eval set: 12\n",
      "Items in test set: 108\n",
      " = 172\n",
      "Number of source documents: 31 total, 15 train, 2 eval 14 test\n",
      "Absolute (training): IR 3.00, N 12.00, R 30.00, HR 7.00\n",
      "Relative (training): IR 0.06, N 0.23, R 0.58, HR 0.13\n",
      "Absolute (eval): IR 3.00, N 0.00, R 0.00, HR 9.00\n",
      "Relative (eval): IR 0.25, N 0.00, R 0.00, HR 0.75\n",
      "Role samples for COUNTERPART in train: 52, eval: 12, test: 108\n",
      "NDCG after 100x random order:\n",
      " > mean ndcg = 0.884233882943 | std = 0.0776996599228\n",
      "NDCG for worst case (inverted best) order:\n",
      " > ndcg = 0.644311172471\n",
      "Accuracy | role : 0.351851851852\n",
      "Accuracy | full : 0.361111111111\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " irrelevant       0.00      0.00      0.00        18\n",
      "    neutral       0.23      0.18      0.20        17\n",
      "   relevant       0.38      0.76      0.50        38\n",
      "     highly       0.39      0.20      0.26        35\n",
      "\n",
      "avg / total       0.29      0.36      0.29       108\n",
      "\n",
      "[[ 0  0 13  5]\n",
      " [ 0  3 11  3]\n",
      " [ 0  6 29  3]\n",
      " [ 0  4 24  7]]\n",
      "> NDCG Score | role | categ  | 0.87404\n",
      "> NDCG Score | role | proba* | 0.75844\n",
      "> NDCG Score | full | categ  | 0.85792\n",
      "> NDCG Score | full | proba* | 0.85810\n",
      "=== INSURER ======\n",
      "Items in training set: 6 (31.58%)\n",
      "Items in eval set: 13\n",
      "Items in test set: 47\n",
      " = 66\n",
      "Number of source documents: 15 total, 5 train, 3 eval 7 test\n",
      "Absolute (training): IR 0.00, N 0.00, R 5.00, HR 1.00\n",
      "Relative (training): IR 0.00, N 0.00, R 0.83, HR 0.17\n",
      "Absolute (eval): IR 1.00, N 1.00, R 3.00, HR 8.00\n",
      "Relative (eval): IR 0.08, N 0.08, R 0.23, HR 0.62\n",
      "Role samples for INSURER in train: 6, eval: 13, test: 47\n",
      "NDCG after 100x random order:\n",
      " > mean ndcg = 0.904892095402 | std = 0.0558435497591\n",
      "NDCG for worst case (inverted best) order:\n",
      " > ndcg = 0.732102608936\n",
      "Accuracy | role : 0.404255319149\n",
      "Accuracy | full : 0.382978723404\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " irrelevant       0.00      0.00      0.00         1\n",
      "    neutral       0.00      0.00      0.00         7\n",
      "   relevant       0.42      0.89      0.58        19\n",
      "     highly       0.33      0.05      0.09        20\n",
      "\n",
      "avg / total       0.31      0.38      0.27        47\n",
      "\n",
      "[[ 0  0  1  0]\n",
      " [ 0  0  6  1]\n",
      " [ 0  1 17  1]\n",
      " [ 0  3 16  1]]\n",
      "> NDCG Score | role | categ  | 0.89620\n",
      "> NDCG Score | role | proba* | 0.94162\n",
      "> NDCG Score | full | categ  | 0.91380\n",
      "> NDCG Score | full | proba* | 0.86692\n",
      "=== SERVICER ======\n",
      "Items in training set: 11 (52.38%)\n",
      "Items in eval set: 10\n",
      "Items in test set: 57\n",
      " = 78\n",
      "Number of source documents: 18 total, 5 train, 3 eval 10 test\n",
      "Absolute (training): IR 0.00, N 5.00, R 6.00, HR 0.00\n",
      "Relative (training): IR 0.00, N 0.45, R 0.55, HR 0.00\n",
      "Absolute (eval): IR 0.00, N 1.00, R 0.00, HR 9.00\n",
      "Relative (eval): IR 0.00, N 0.10, R 0.00, HR 0.90\n",
      "Role samples for SERVICER in train: 11, eval: 10, test: 57\n",
      "NDCG after 100x random order:\n",
      " > mean ndcg = 0.969479811062 | std = 0.0343386828391\n",
      "NDCG for worst case (inverted best) order:\n",
      " > ndcg = 0.907796256426\n",
      "Accuracy | role : 0.666666666667\n",
      "Accuracy | full : 0.649122807018\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " irrelevant       0.00      0.00      0.00         3\n",
      "    neutral       0.33      0.11      0.17         9\n",
      "   relevant       0.70      0.92      0.80        38\n",
      "     highly       0.25      0.14      0.18         7\n",
      "\n",
      "avg / total       0.55      0.65      0.58        57\n",
      "\n",
      "[[ 0  1  2  0]\n",
      " [ 0  1  7  1]\n",
      " [ 0  1 35  2]\n",
      " [ 0  0  6  1]]\n",
      "> NDCG Score | role | categ  | 0.85663\n",
      "> NDCG Score | role | proba* | 0.85879\n",
      "> NDCG Score | full | categ  | 0.87694\n",
      "> NDCG Score | full | proba* | 0.89084\n",
      "=== TRUSTEE ======\n",
      "Items in training set: 322 (76.67%)\n",
      "Items in eval set: 98\n",
      "Items in test set: 304\n",
      " = 724\n",
      "Number of source documents: 40 total, 18 train, 3 eval 19 test\n",
      "Absolute (training): IR 17.00, N 159.00, R 74.00, HR 72.00\n",
      "Relative (training): IR 0.05, N 0.49, R 0.23, HR 0.22\n",
      "Absolute (eval): IR 4.00, N 5.00, R 5.00, HR 84.00\n",
      "Relative (eval): IR 0.04, N 0.05, R 0.05, HR 0.86\n",
      "Role samples for TRUSTEE in train: 322, eval: 98, test: 304\n",
      "NDCG after 100x random order:\n",
      " > mean ndcg = 0.970859184546 | std = 0.0151932449023\n",
      "NDCG for worst case (inverted best) order:\n",
      " > ndcg = 0.8291049398\n",
      "Accuracy | role : 0.388157894737\n",
      "Accuracy | full : 0.434210526316\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " irrelevant       0.00      0.00      0.00         9\n",
      "    neutral       0.18      0.53      0.27        47\n",
      "   relevant       0.37      0.15      0.22       124\n",
      "     highly       0.77      0.71      0.74       124\n",
      "\n",
      "avg / total       0.49      0.43      0.43       304\n",
      "\n",
      "[[ 0  4  4  1]\n",
      " [ 0 25 10 12]\n",
      " [ 0 91 19 14]\n",
      " [ 0 17 19 88]]\n",
      "> NDCG Score | role | categ  | 0.96700\n",
      "> NDCG Score | role | proba* | 0.97133\n",
      "> NDCG Score | full | categ  | 0.98434\n",
      "> NDCG Score | full | proba* | 0.97496\n",
      "=== ISSUER ======\n",
      "Items in training set: 119 (92.25%)\n",
      "Items in eval set: 10\n",
      "Items in test set: 98\n",
      " = 227\n",
      "Number of source documents: 46 total, 21 train, 3 eval 22 test\n",
      "Absolute (training): IR 28.00, N 45.00, R 27.00, HR 19.00\n",
      "Relative (training): IR 0.24, N 0.38, R 0.23, HR 0.16\n",
      "Absolute (eval): IR 4.00, N 0.00, R 3.00, HR 3.00\n",
      "Relative (eval): IR 0.40, N 0.00, R 0.30, HR 0.30\n",
      "Role samples for ISSUER in train: 119, eval: 10, test: 98\n",
      "NDCG after 100x random order:\n",
      " > mean ndcg = 0.72732587653 | std = 0.11081633046\n",
      "NDCG for worst case (inverted best) order:\n",
      " > ndcg = 0.493639129902\n",
      "Accuracy | role : 0.275510204082\n",
      "Accuracy | full : 0.255102040816\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " irrelevant       0.00      0.00      0.00        21\n",
      "    neutral       0.29      0.07      0.12        27\n",
      "   relevant       0.25      0.74      0.37        27\n",
      "     highly       0.27      0.13      0.18        23\n",
      "\n",
      "avg / total       0.21      0.26      0.18        98\n",
      "\n",
      "[[ 0  0 19  2]\n",
      " [ 0  2 21  4]\n",
      " [ 0  5 20  2]\n",
      " [ 0  0 20  3]]\n",
      "> NDCG Score | role | categ  | 0.70812\n",
      "> NDCG Score | role | proba* | 0.94225\n",
      "> NDCG Score | full | categ  | 0.80192\n",
      "> NDCG Score | full | proba* | 0.80606\n",
      "=== UNDERWRITER ======\n",
      "Items in training set: 17 (80.95%)\n",
      "Items in eval set: 4\n",
      "Items in test set: 40\n",
      " = 61\n",
      "Number of source documents: 16 total, 5 train, 2 eval 9 test\n",
      "Absolute (training): IR 0.00, N 0.00, R 14.00, HR 3.00\n",
      "Relative (training): IR 0.00, N 0.00, R 0.82, HR 0.18\n",
      "Absolute (eval): IR 0.00, N 0.00, R 0.00, HR 4.00\n",
      "Relative (eval): IR 0.00, N 0.00, R 0.00, HR 1.00\n",
      "Role samples for UNDERWRITER in train: 17, eval: 4, test: 40\n",
      "NDCG after 100x random order:\n",
      " > mean ndcg = 1.0 | std = 0.0\n",
      "NDCG for worst case (inverted best) order:\n",
      " > ndcg = 1.0\n",
      "Accuracy | role : 0.375\n",
      "Accuracy | full : 0.375\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " irrelevant       0.00      0.00      0.00         3\n",
      "    neutral       0.00      0.00      0.00         2\n",
      "   relevant       0.29      0.33      0.31        15\n",
      "     highly       0.43      0.50      0.47        20\n",
      "\n",
      "avg / total       0.33      0.38      0.35        40\n",
      "\n",
      "[[ 0  0  2  1]\n",
      " [ 0  0  0  2]\n",
      " [ 0  0  5 10]\n",
      " [ 0  0 10 10]]\n",
      "> NDCG Score | role | categ  | 0.86908\n",
      "> NDCG Score | role | proba* | 0.96721\n",
      "> NDCG Score | full | categ  | 0.94240\n",
      "> NDCG Score | full | proba* | 0.89373\n",
      "=== SELLER ======\n",
      "Items in training set: 16 (80.00%)\n",
      "Items in eval set: 4\n",
      "Items in test set: 49\n",
      " = 69\n",
      "Number of source documents: 19 total, 7 train, 3 eval 9 test\n",
      "Absolute (training): IR 0.00, N 0.00, R 12.00, HR 4.00\n",
      "Relative (training): IR 0.00, N 0.00, R 0.75, HR 0.25\n",
      "Absolute (eval): IR 0.00, N 1.00, R 2.00, HR 1.00\n",
      "Relative (eval): IR 0.00, N 0.25, R 0.50, HR 0.25\n",
      "Role samples for SELLER in train: 16, eval: 4, test: 49\n",
      "NDCG after 100x random order:\n",
      " > mean ndcg = 0.924506804712 | std = 0.0543199064541\n",
      "NDCG for worst case (inverted best) order:\n",
      " > ndcg = 0.852111686298\n",
      "Accuracy | role : 0.34693877551\n",
      "Accuracy | full : 0.367346938776\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " irrelevant       0.00      0.00      0.00         4\n",
      "    neutral       0.20      0.10      0.13        10\n",
      "   relevant       0.29      0.53      0.38        17\n",
      "     highly       0.62      0.44      0.52        18\n",
      "\n",
      "avg / total       0.37      0.37      0.35        49\n",
      "\n",
      "[[ 0  0  4  0]\n",
      " [ 0  1  8  1]\n",
      " [ 0  4  9  4]\n",
      " [ 0  0 10  8]]\n",
      "> NDCG Score | role | categ  | 0.80424\n",
      "> NDCG Score | role | proba* | 0.89769\n",
      "> NDCG Score | full | categ  | 0.92201\n",
      "> NDCG Score | full | proba* | 0.90073\n",
      "=== AFFILIATE ======\n",
      "Items in training set: 145 (77.96%)\n",
      "Items in eval set: 41\n",
      "Items in test set: 129\n",
      " = 315\n",
      "Number of source documents: 41 total, 19 train, 3 eval 19 test\n",
      "Absolute (training): IR 18.00, N 39.00, R 56.00, HR 32.00\n",
      "Relative (training): IR 0.12, N 0.27, R 0.39, HR 0.22\n",
      "Absolute (eval): IR 8.00, N 1.00, R 6.00, HR 26.00\n",
      "Relative (eval): IR 0.20, N 0.02, R 0.15, HR 0.63\n",
      "Role samples for AFFILIATE in train: 145, eval: 41, test: 129\n",
      "NDCG after 100x random order:\n",
      " > mean ndcg = 0.887745749254 | std = 0.0441486456804\n",
      "NDCG for worst case (inverted best) order:\n",
      " > ndcg = 0.667825975875\n",
      "Accuracy | role : 0.356589147287\n",
      "Accuracy | full : 0.565891472868\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " irrelevant       0.00      0.00      0.00        17\n",
      "    neutral       0.25      0.17      0.20        12\n",
      "   relevant       0.49      0.80      0.61        54\n",
      "     highly       0.82      0.61      0.70        46\n",
      "\n",
      "avg / total       0.52      0.57      0.52       129\n",
      "\n",
      "[[ 0  1 16  0]\n",
      " [ 0  2 10  0]\n",
      " [ 0  5 43  6]\n",
      " [ 0  0 18 28]]\n",
      "> NDCG Score | role | categ  | 0.95729\n",
      "> NDCG Score | role | proba* | 0.93120\n",
      "> NDCG Score | full | categ  | 0.95672\n",
      "> NDCG Score | full | proba* | 0.97366\n",
      "TOTAL NDCG | role | categ  | 0.96267\n",
      "TOTAL NDCG | role | proba* | 0.95574\n",
      "TOTAL NDCG | full | categ  | 0.95684\n",
      "TOTAL NDCG | full | proba* | 0.92164\n",
      "baseline_rand 10\n",
      "baseline_worst 10\n",
      "ndcg_role 10\n",
      "ndcg_full 10\n",
      "ndcg_role_proba 10\n",
      "ndcg_full_proba 10\n",
      "acc_role 10\n",
      "acc_full 10\n",
      "f1_role 10\n",
      "f1_full 10\n",
      "\n",
      "\n",
      "==========================================================================\n",
      "===                      CROSSEVAL ITERATION 4/5                     =====\n",
      "==========================================================================\n",
      "\n",
      "\n",
      "Items in training set: 863 (88.51%)\n",
      "Items in eval set: 112\n",
      "Items in test set: 900\n",
      " = 1875\n",
      "Number of source documents: 50 total, 22 train, 3 eval 25 test\n",
      "Absolute (training): IR 77.00, N 267.00, R 229.00, HR 290.00\n",
      "Relative (training): IR 0.09, N 0.31, R 0.27, HR 0.34\n",
      "Absolute (eval): IR 13.00, N 40.00, R 54.00, HR 5.00\n",
      "Relative (eval): IR 0.12, N 0.36, R 0.48, HR 0.04\n",
      "Role samples for GUARANTOR in train: 15, eval: 19, test: 28\n",
      "Role samples for SERVICER in train: 18, eval: 3, test: 57\n",
      "Role samples for AGENT in train: 58, eval: 3, test: 40\n",
      "Role samples for COUNTERPART in train: 59, eval: 5, test: 108\n",
      "Role samples for TRUSTEE in train: 381, eval: 39, test: 304\n",
      "Role samples for ISSUER in train: 119, eval: 10, test: 98\n",
      "Role samples for UNDERWRITER in train: 14, eval: 7, test: 40\n",
      "Role samples for SELLER in train: 20, eval: 0, test: 49\n",
      "Role samples for INSURER in train: 19, eval: 0, test: 47\n",
      "Role samples for AFFILIATE in train: 160, eval: 26, test: 129\n",
      "=== GUARANTOR ======\n",
      "Items in training set: 15 (44.12%)\n",
      "Items in eval set: 19\n",
      "Items in test set: 28\n",
      " = 62\n",
      "Number of source documents: 15 total, 3 train, 3 eval 9 test\n",
      "Absolute (training): IR 1.00, N 1.00, R 5.00, HR 8.00\n",
      "Relative (training): IR 0.07, N 0.07, R 0.33, HR 0.53\n",
      "Absolute (eval): IR 0.00, N 2.00, R 17.00, HR 0.00\n",
      "Relative (eval): IR 0.00, N 0.11, R 0.89, HR 0.00\n",
      "Role samples for GUARANTOR in train: 15, eval: 19, test: 28\n",
      "NDCG after 100x random order:\n",
      " > mean ndcg = 0.973234681094 | std = 0.0248962120115\n",
      "NDCG for worst case (inverted best) order:\n",
      " > ndcg = 0.896183295414\n",
      "Accuracy | role : 0.785714285714\n",
      "Accuracy | full : 0.571428571429\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " irrelevant       0.00      0.00      0.00         0\n",
      "    neutral       0.00      0.00      0.00         3\n",
      "   relevant       0.73      0.73      0.73        22\n",
      "     highly       0.00      0.00      0.00         3\n",
      "\n",
      "avg / total       0.57      0.57      0.57        28\n",
      "\n",
      "[[ 0  0  0  0]\n",
      " [ 0  0  3  0]\n",
      " [ 0  5 16  1]\n",
      " [ 0  0  3  0]]\n",
      "> NDCG Score | role | categ  | 0.84067\n",
      "> NDCG Score | role | proba* | 0.91874\n",
      "> NDCG Score | full | categ  | 0.85645\n",
      "> NDCG Score | full | proba* | 0.88964\n",
      "=== AGENT ======\n",
      "Items in training set: 58 (95.08%)\n",
      "Items in eval set: 3\n",
      "Items in test set: 40\n",
      " = 101\n",
      "Number of source documents: 25 total, 14 train, 2 eval 9 test\n",
      "Absolute (training): IR 3.00, N 33.00, R 17.00, HR 5.00\n",
      "Relative (training): IR 0.05, N 0.57, R 0.29, HR 0.09\n",
      "Absolute (eval): IR 0.00, N 2.00, R 1.00, HR 0.00\n",
      "Relative (eval): IR 0.00, N 0.67, R 0.33, HR 0.00\n",
      "Role samples for AGENT in train: 58, eval: 3, test: 40\n",
      "NDCG after 100x random order:\n",
      " > mean ndcg = 0.968489675054 | std = 0.0470106850922\n",
      "NDCG for worst case (inverted best) order:\n",
      " > ndcg = 0.898353790495\n",
      "Accuracy | role : 0.375\n",
      "Accuracy | full : 0.225\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " irrelevant       0.00      0.00      0.00         4\n",
      "    neutral       0.00      0.00      0.00         8\n",
      "   relevant       0.26      0.47      0.33        15\n",
      "     highly       0.18      0.15      0.17        13\n",
      "\n",
      "avg / total       0.16      0.23      0.18        40\n",
      "\n",
      "[[ 0  1  3  0]\n",
      " [ 0  0  6  2]\n",
      " [ 0  1  7  7]\n",
      " [ 0  0 11  2]]\n",
      "> NDCG Score | role | categ  | 0.89290\n",
      "> NDCG Score | role | proba* | 0.75407\n",
      "> NDCG Score | full | categ  | 0.86264\n",
      "> NDCG Score | full | proba* | 0.85163\n",
      "=== COUNTERPART ======\n",
      "Items in training set: 59 (92.19%)\n",
      "Items in eval set: 5\n",
      "Items in test set: 108\n",
      " = 172\n",
      "Number of source documents: 31 total, 15 train, 2 eval 14 test\n",
      "Absolute (training): IR 6.00, N 10.00, R 28.00, HR 15.00\n",
      "Relative (training): IR 0.10, N 0.17, R 0.47, HR 0.25\n",
      "Absolute (eval): IR 0.00, N 2.00, R 2.00, HR 1.00\n",
      "Relative (eval): IR 0.00, N 0.40, R 0.40, HR 0.20\n",
      "Role samples for COUNTERPART in train: 59, eval: 5, test: 108\n",
      "NDCG after 100x random order:\n",
      " > mean ndcg = 0.879456855052 | std = 0.0553813928767\n",
      "NDCG for worst case (inverted best) order:\n",
      " > ndcg = 0.772173977441\n",
      "Accuracy | role : 0.351851851852\n",
      "Accuracy | full : 0.388888888889\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " irrelevant       0.00      0.00      0.00        18\n",
      "    neutral       0.00      0.00      0.00        17\n",
      "   relevant       0.40      0.89      0.55        38\n",
      "     highly       0.42      0.23      0.30        35\n",
      "\n",
      "avg / total       0.28      0.39      0.29       108\n",
      "\n",
      "[[ 0  0 13  5]\n",
      " [ 0  0 13  4]\n",
      " [ 0  2 34  2]\n",
      " [ 0  1 26  8]]\n",
      "> NDCG Score | role | categ  | 0.87404\n",
      "> NDCG Score | role | proba* | 0.85532\n",
      "> NDCG Score | full | categ  | 0.90740\n",
      "> NDCG Score | full | proba* | 0.80905\n",
      "=== INSURER ======\n",
      "Items in training set: 19 (100.00%)\n",
      "Items in eval set: 0\n",
      "Items in test set: 47\n",
      " = 66\n",
      "Number of source documents: 15 total, 8 train, 0 eval 7 test\n",
      "Absolute (training): IR 1.00, N 1.00, R 8.00, HR 9.00\n",
      "Relative (training): IR 0.05, N 0.05, R 0.42, HR 0.47\n",
      "Absolute (eval): IR 0.00, N 0.00, R 0.00, HR 0.00\n",
      "Relative (eval): IR nan, N nan, R nan, HR nan\n",
      "Role samples for INSURER in train: 19, eval: 0, test: 47\n",
      "NDCG after 100x random order:\n",
      " > mean ndcg = nan | std = nan\n",
      "NDCG for worst case (inverted best) order:\n",
      " > ndcg = nan\n",
      "Accuracy | role : 0.404255319149\n",
      "Accuracy | full : 0.36170212766\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " irrelevant       0.00      0.00      0.00         1\n",
      "    neutral       0.00      0.00      0.00         7\n",
      "   relevant       0.40      0.89      0.55        19\n",
      "     highly       0.00      0.00      0.00        20\n",
      "\n",
      "avg / total       0.16      0.36      0.22        47\n",
      "\n",
      "[[ 0  0  1  0]\n",
      " [ 0  0  6  1]\n",
      " [ 0  0 17  2]\n",
      " [ 0  1 19  0]]\n",
      "> NDCG Score | role | categ  | 0.89620\n",
      "> NDCG Score | role | proba* | 0.88954\n",
      "> NDCG Score | full | categ  | 0.88893\n",
      "> NDCG Score | full | proba* | 0.88058\n",
      "=== SERVICER ======\n",
      "Items in training set: 18 (85.71%)\n",
      "Items in eval set: 3\n",
      "Items in test set: 57\n",
      " = 78\n",
      "Number of source documents: 18 total, 7 train, 1 eval 10 test\n",
      "Absolute (training): IR 0.00, N 6.00, R 3.00, HR 9.00\n",
      "Relative (training): IR 0.00, N 0.33, R 0.17, HR 0.50\n",
      "Absolute (eval): IR 0.00, N 0.00, R 3.00, HR 0.00\n",
      "Relative (eval): IR 0.00, N 0.00, R 1.00, HR 0.00\n",
      "Role samples for SERVICER in train: 18, eval: 3, test: 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tim/Uni/HPI/workspace/FEII/code/feiii_data.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  rating_agg.sum()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG after 100x random order:\n",
      " > mean ndcg = 1.0 | std = 0.0\n",
      "NDCG for worst case (inverted best) order:\n",
      " > ndcg = 1.0\n",
      "Accuracy | role : 0.122807017544\n",
      "Accuracy | full : 0.649122807018\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " irrelevant       0.00      0.00      0.00         3\n",
      "    neutral       0.00      0.00      0.00         9\n",
      "   relevant       0.68      0.95      0.79        38\n",
      "     highly       0.25      0.14      0.18         7\n",
      "\n",
      "avg / total       0.48      0.65      0.55        57\n",
      "\n",
      "[[ 0  0  3  0]\n",
      " [ 0  0  8  1]\n",
      " [ 0  0 36  2]\n",
      " [ 0  0  6  1]]\n",
      "> NDCG Score | role | categ  | 0.85663\n",
      "> NDCG Score | role | proba* | 0.84422\n",
      "> NDCG Score | full | categ  | 0.87521\n",
      "> NDCG Score | full | proba* | 0.89387\n",
      "=== TRUSTEE ======\n",
      "Items in training set: 381 (90.71%)\n",
      "Items in eval set: 39\n",
      "Items in test set: 304\n",
      " = 724\n",
      "Number of source documents: 40 total, 18 train, 3 eval 19 test\n",
      "Absolute (training): IR 20.00, N 143.00, R 62.00, HR 156.00\n",
      "Relative (training): IR 0.05, N 0.38, R 0.16, HR 0.41\n",
      "Absolute (eval): IR 1.00, N 21.00, R 17.00, HR 0.00\n",
      "Relative (eval): IR 0.03, N 0.54, R 0.44, HR 0.00\n",
      "Role samples for TRUSTEE in train: 381, eval: 39, test: 304\n",
      "NDCG after 100x random order:\n",
      " > mean ndcg = 0.888415310269 | std = 0.0323938687897\n",
      "NDCG for worst case (inverted best) order:\n",
      " > ndcg = 0.760383961477\n",
      "Accuracy | role : 0.480263157895\n",
      "Accuracy | full : 0.394736842105\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " irrelevant       0.00      0.00      0.00         9\n",
      "    neutral       0.14      0.28      0.19        47\n",
      "   relevant       0.00      0.00      0.00       124\n",
      "     highly       0.51      0.86      0.64       124\n",
      "\n",
      "avg / total       0.23      0.39      0.29       304\n",
      "\n",
      "[[  0   4   3   2]\n",
      " [  0  13   1  33]\n",
      " [  0  57   0  67]\n",
      " [  0  17   0 107]]\n",
      "> NDCG Score | role | categ  | 0.97345\n",
      "> NDCG Score | role | proba* | 0.97097\n",
      "> NDCG Score | full | categ  | 0.97739\n",
      "> NDCG Score | full | proba* | 0.97278\n",
      "=== ISSUER ======\n",
      "Items in training set: 119 (92.25%)\n",
      "Items in eval set: 10\n",
      "Items in test set: 98\n",
      " = 227\n",
      "Number of source documents: 46 total, 21 train, 3 eval 22 test\n",
      "Absolute (training): IR 30.00, N 41.00, R 28.00, HR 20.00\n",
      "Relative (training): IR 0.25, N 0.34, R 0.24, HR 0.17\n",
      "Absolute (eval): IR 2.00, N 4.00, R 2.00, HR 2.00\n",
      "Relative (eval): IR 0.20, N 0.40, R 0.20, HR 0.20\n",
      "Role samples for ISSUER in train: 119, eval: 10, test: 98\n",
      "NDCG after 100x random order:\n",
      " > mean ndcg = 0.755437577556 | std = 0.086526413868\n",
      "NDCG for worst case (inverted best) order:\n",
      " > ndcg = 0.529948018754\n",
      "Accuracy | role : 0.285714285714\n",
      "Accuracy | full : 0.234693877551\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " irrelevant       0.00      0.00      0.00        21\n",
      "    neutral       0.12      0.04      0.06        27\n",
      "   relevant       0.26      0.78      0.39        27\n",
      "     highly       0.12      0.04      0.06        23\n",
      "\n",
      "avg / total       0.13      0.23      0.14        98\n",
      "\n",
      "[[ 0  0 18  3]\n",
      " [ 0  1 23  3]\n",
      " [ 0  5 21  1]\n",
      " [ 0  2 20  1]]\n",
      "> NDCG Score | role | categ  | 0.90284\n",
      "> NDCG Score | role | proba* | 0.92821\n",
      "> NDCG Score | full | categ  | 0.73440\n",
      "> NDCG Score | full | proba* | 0.83419\n",
      "=== UNDERWRITER ======\n",
      "Items in training set: 14 (66.67%)\n",
      "Items in eval set: 7\n",
      "Items in test set: 40\n",
      " = 61\n",
      "Number of source documents: 16 total, 6 train, 1 eval 9 test\n",
      "Absolute (training): IR 0.00, N 0.00, R 7.00, HR 7.00\n",
      "Relative (training): IR 0.00, N 0.00, R 0.50, HR 0.50\n",
      "Absolute (eval): IR 0.00, N 0.00, R 7.00, HR 0.00\n",
      "Relative (eval): IR 0.00, N 0.00, R 1.00, HR 0.00\n",
      "Role samples for UNDERWRITER in train: 14, eval: 7, test: 40\n",
      "NDCG after 100x random order:\n",
      " > mean ndcg = 1.0 | std = 0.0\n",
      "NDCG for worst case (inverted best) order:\n",
      " > ndcg = 1.0\n",
      "Accuracy | role : 0.375\n",
      "Accuracy | full : 0.225\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " irrelevant       0.00      0.00      0.00         3\n",
      "    neutral       0.12      1.00      0.21         2\n",
      "   relevant       0.29      0.33      0.31        15\n",
      "     highly       0.33      0.10      0.15        20\n",
      "\n",
      "avg / total       0.28      0.23      0.20        40\n",
      "\n",
      "[[ 0  1  2  0]\n",
      " [ 0  2  0  0]\n",
      " [ 0  6  5  4]\n",
      " [ 0  8 10  2]]\n",
      "> NDCG Score | role | categ  | 0.86908\n",
      "> NDCG Score | role | proba* | 0.93189\n",
      "> NDCG Score | full | categ  | 0.90802\n",
      "> NDCG Score | full | proba* | 0.88910\n",
      "=== SELLER ======\n",
      "Items in training set: 20 (100.00%)\n",
      "Items in eval set: 0\n",
      "Items in test set: 49\n",
      " = 69\n",
      "Number of source documents: 19 total, 10 train, 0 eval 9 test\n",
      "Absolute (training): IR 0.00, N 1.00, R 14.00, HR 5.00\n",
      "Relative (training): IR 0.00, N 0.05, R 0.70, HR 0.25\n",
      "Absolute (eval): IR 0.00, N 0.00, R 0.00, HR 0.00\n",
      "Relative (eval): IR nan, N nan, R nan, HR nan\n",
      "Role samples for SELLER in train: 20, eval: 0, test: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tim/Uni/HPI/workspace/FEII/code/feiii_data.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  rating_agg.sum()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG after 100x random order:\n",
      " > mean ndcg = nan | std = nan\n",
      "NDCG for worst case (inverted best) order:\n",
      " > ndcg = nan\n",
      "Accuracy | role : 0.34693877551\n",
      "Accuracy | full : 0.367346938776\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " irrelevant       0.00      0.00      0.00         4\n",
      "    neutral       0.17      0.10      0.12        10\n",
      "   relevant       0.31      0.59      0.41        17\n",
      "     highly       0.64      0.39      0.48        18\n",
      "\n",
      "avg / total       0.38      0.37      0.34        49\n",
      "\n",
      "[[ 0  0  4  0]\n",
      " [ 0  1  8  1]\n",
      " [ 0  4 10  3]\n",
      " [ 0  1 10  7]]\n",
      "> NDCG Score | role | categ  | 0.80424\n",
      "> NDCG Score | role | proba* | 0.86926\n",
      "> NDCG Score | full | categ  | 0.92306\n",
      "> NDCG Score | full | proba* | 0.89936\n",
      "=== AFFILIATE ======\n",
      "Items in training set: 160 (86.02%)\n",
      "Items in eval set: 26\n",
      "Items in test set: 129\n",
      " = 315\n",
      "Number of source documents: 41 total, 20 train, 2 eval 19 test\n",
      "Absolute (training): IR 16.00, N 31.00, R 57.00, HR 56.00\n",
      "Relative (training): IR 0.10, N 0.19, R 0.36, HR 0.35\n",
      "Absolute (eval): IR 10.00, N 9.00, R 5.00, HR 2.00\n",
      "Relative (eval): IR 0.38, N 0.35, R 0.19, HR 0.08\n",
      "Role samples for AFFILIATE in train: 160, eval: 26, test: 129\n",
      "NDCG after 100x random order:\n",
      " > mean ndcg = 0.669270868305 | std = 0.0861370718519\n",
      "NDCG for worst case (inverted best) order:\n",
      " > ndcg = 0.444774013296\n",
      "Accuracy | role : 0.480620155039\n",
      "Accuracy | full : 0.472868217054\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " irrelevant       0.00      0.00      0.00        17\n",
      "    neutral       0.00      0.00      0.00        12\n",
      "   relevant       0.49      0.83      0.62        54\n",
      "     highly       0.73      0.35      0.47        46\n",
      "\n",
      "avg / total       0.47      0.47      0.43       129\n",
      "\n",
      "[[ 0  0 17  0]\n",
      " [ 0  0 12  0]\n",
      " [ 0  3 45  6]\n",
      " [ 0 13 17 16]]\n",
      "> NDCG Score | role | categ  | 0.93349\n",
      "> NDCG Score | role | proba* | 0.93822\n",
      "> NDCG Score | full | categ  | 0.92444\n",
      "> NDCG Score | full | proba* | 0.92924\n",
      "TOTAL NDCG | role | categ  | 0.96292\n",
      "TOTAL NDCG | role | proba* | 0.95791\n",
      "TOTAL NDCG | full | categ  | 0.93494\n",
      "TOTAL NDCG | full | proba* | 0.95101\n",
      "baseline_rand 10\n",
      "baseline_worst 10\n",
      "ndcg_role 10\n",
      "ndcg_full 10\n",
      "ndcg_role_proba 10\n",
      "ndcg_full_proba 10\n",
      "acc_role 10\n",
      "acc_full 10\n",
      "f1_role 10\n",
      "f1_full 10\n",
      "\n",
      "\n",
      "==========================================================================\n",
      "===                      CROSSEVAL ITERATION 5/5                     =====\n",
      "==========================================================================\n",
      "\n",
      "\n",
      "Items in training set: 866 (88.82%)\n",
      "Items in eval set: 109\n",
      "Items in test set: 900\n",
      " = 1875\n",
      "Number of source documents: 50 total, 22 train, 3 eval 25 test\n",
      "Absolute (training): IR 86.00, N 247.00, R 250.00, HR 283.00\n",
      "Relative (training): IR 0.10, N 0.29, R 0.29, HR 0.33\n",
      "Absolute (eval): IR 4.00, N 60.00, R 33.00, HR 12.00\n",
      "Relative (eval): IR 0.04, N 0.55, R 0.30, HR 0.11\n",
      "Role samples for GUARANTOR in train: 34, eval: 0, test: 28\n",
      "Role samples for SERVICER in train: 19, eval: 2, test: 57\n",
      "Role samples for AGENT in train: 46, eval: 15, test: 40\n",
      "Role samples for COUNTERPART in train: 63, eval: 1, test: 108\n",
      "Role samples for TRUSTEE in train: 364, eval: 56, test: 304\n",
      "Role samples for ISSUER in train: 111, eval: 18, test: 98\n",
      "Role samples for UNDERWRITER in train: 19, eval: 2, test: 40\n",
      "Role samples for SELLER in train: 17, eval: 3, test: 49\n",
      "Role samples for INSURER in train: 18, eval: 1, test: 47\n",
      "Role samples for AFFILIATE in train: 175, eval: 11, test: 129\n",
      "=== GUARANTOR ======\n",
      "Items in training set: 34 (100.00%)\n",
      "Items in eval set: 0\n",
      "Items in test set: 28\n",
      " = 62\n",
      "Number of source documents: 15 total, 6 train, 0 eval 9 test\n",
      "Absolute (training): IR 1.00, N 3.00, R 22.00, HR 8.00\n",
      "Relative (training): IR 0.03, N 0.09, R 0.65, HR 0.24\n",
      "Absolute (eval): IR 0.00, N 0.00, R 0.00, HR 0.00\n",
      "Relative (eval): IR nan, N nan, R nan, HR nan\n",
      "Role samples for GUARANTOR in train: 34, eval: 0, test: 28\n",
      "NDCG after 100x random order:\n",
      " > mean ndcg = nan | std = nan\n",
      "NDCG for worst case (inverted best) order:\n",
      " > ndcg = nan\n",
      "Accuracy | role : 0.785714285714\n",
      "Accuracy | full : 0.571428571429\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " irrelevant       0.00      0.00      0.00         0\n",
      "    neutral       0.00      0.00      0.00         3\n",
      "   relevant       0.73      0.73      0.73        22\n",
      "     highly       0.00      0.00      0.00         3\n",
      "\n",
      "avg / total       0.57      0.57      0.57        28\n",
      "\n",
      "[[ 0  0  0  0]\n",
      " [ 0  0  3  0]\n",
      " [ 0  5 16  1]\n",
      " [ 0  0  3  0]]\n",
      "> NDCG Score | role | categ  | 0.84067\n",
      "> NDCG Score | role | proba* | 0.89775\n",
      "> NDCG Score | full | categ  | 0.85645\n",
      "> NDCG Score | full | proba* | 0.88964\n",
      "=== AGENT ======\n",
      "Items in training set: 46 (75.41%)\n",
      "Items in eval set: 15\n",
      "Items in test set: 40\n",
      " = 101\n",
      "Number of source documents: 25 total, 13 train, 3 eval 9 test\n",
      "Absolute (training): IR 3.00, N 25.00, R 14.00, HR 4.00\n",
      "Relative (training): IR 0.07, N 0.54, R 0.30, HR 0.09\n",
      "Absolute (eval): IR 0.00, N 10.00, R 4.00, HR 1.00\n",
      "Relative (eval): IR 0.00, N 0.67, R 0.27, HR 0.07\n",
      "Role samples for AGENT in train: 46, eval: 15, test: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tim/Uni/HPI/workspace/FEII/code/feiii_data.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  rating_agg.sum()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG after 100x random order:\n",
      " > mean ndcg = 0.830487445166 | std = 0.0572631031837\n",
      "NDCG for worst case (inverted best) order:\n",
      " > ndcg = 0.73607743137\n",
      "Accuracy | role : 0.2\n",
      "Accuracy | full : 0.225\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " irrelevant       0.00      0.00      0.00         4\n",
      "    neutral       0.00      0.00      0.00         8\n",
      "   relevant       0.26      0.47      0.33        15\n",
      "     highly       0.15      0.15      0.15        13\n",
      "\n",
      "avg / total       0.15      0.23      0.18        40\n",
      "\n",
      "[[ 0  0  3  1]\n",
      " [ 0  0  6  2]\n",
      " [ 0  0  7  8]\n",
      " [ 0  0 11  2]]\n",
      "> NDCG Score | role | categ  | 0.89290\n",
      "> NDCG Score | role | proba* | 0.90041\n",
      "> NDCG Score | full | categ  | 0.88892\n",
      "> NDCG Score | full | proba* | 0.83853\n",
      "=== COUNTERPART ======\n",
      "Items in training set: 63 (98.44%)\n",
      "Items in eval set: 1\n",
      "Items in test set: 108\n",
      " = 172\n",
      "Number of source documents: 31 total, 16 train, 1 eval 14 test\n",
      "Absolute (training): IR 6.00, N 12.00, R 29.00, HR 16.00\n",
      "Relative (training): IR 0.10, N 0.19, R 0.46, HR 0.25\n",
      "Absolute (eval): IR 0.00, N 0.00, R 1.00, HR 0.00\n",
      "Relative (eval): IR 0.00, N 0.00, R 1.00, HR 0.00\n",
      "Role samples for COUNTERPART in train: 63, eval: 1, test: 108\n",
      "NDCG after 100x random order:\n",
      " > mean ndcg = 1.0 | std = 0.0\n",
      "NDCG for worst case (inverted best) order:\n",
      " > ndcg = 1.0\n",
      "Accuracy | role : 0.342592592593\n",
      "Accuracy | full : 0.388888888889\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " irrelevant       0.00      0.00      0.00        18\n",
      "    neutral       0.00      0.00      0.00        17\n",
      "   relevant       0.40      0.89      0.55        38\n",
      "     highly       0.42      0.23      0.30        35\n",
      "\n",
      "avg / total       0.28      0.39      0.29       108\n",
      "\n",
      "[[ 0  0 13  5]\n",
      " [ 0  0 13  4]\n",
      " [ 0  2 34  2]\n",
      " [ 0  1 26  8]]\n",
      "> NDCG Score | role | categ  | 0.90771\n",
      "> NDCG Score | role | proba* | 0.86976\n",
      "> NDCG Score | full | categ  | 0.90740\n",
      "> NDCG Score | full | proba* | 0.81146\n",
      "=== INSURER ======\n",
      "Items in training set: 18 (94.74%)\n",
      "Items in eval set: 1\n",
      "Items in test set: 47\n",
      " = 66\n",
      "Number of source documents: 15 total, 7 train, 1 eval 7 test\n",
      "Absolute (training): IR 1.00, N 1.00, R 7.00, HR 9.00\n",
      "Relative (training): IR 0.06, N 0.06, R 0.39, HR 0.50\n",
      "Absolute (eval): IR 0.00, N 0.00, R 1.00, HR 0.00\n",
      "Relative (eval): IR 0.00, N 0.00, R 1.00, HR 0.00\n",
      "Role samples for INSURER in train: 18, eval: 1, test: 47\n",
      "NDCG after 100x random order:\n",
      " > mean ndcg = 1.0 | std = 0.0\n",
      "NDCG for worst case (inverted best) order:\n",
      " > ndcg = 1.0\n",
      "Accuracy | role : 0.425531914894\n",
      "Accuracy | full : 0.36170212766\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " irrelevant       0.00      0.00      0.00         1\n",
      "    neutral       0.00      0.00      0.00         7\n",
      "   relevant       0.40      0.89      0.55        19\n",
      "     highly       0.00      0.00      0.00        20\n",
      "\n",
      "avg / total       0.16      0.36      0.22        47\n",
      "\n",
      "[[ 0  0  1  0]\n",
      " [ 0  0  6  1]\n",
      " [ 0  0 17  2]\n",
      " [ 0  1 19  0]]\n",
      "> NDCG Score | role | categ  | 0.89620\n",
      "> NDCG Score | role | proba* | 0.88526\n",
      "> NDCG Score | full | categ  | 0.88893\n",
      "> NDCG Score | full | proba* | 0.86924\n",
      "=== SERVICER ======\n",
      "Items in training set: 19 (90.48%)\n",
      "Items in eval set: 2\n",
      "Items in test set: 57\n",
      " = 78\n",
      "Number of source documents: 18 total, 7 train, 1 eval 10 test\n",
      "Absolute (training): IR 0.00, N 4.00, R 6.00, HR 9.00\n",
      "Relative (training): IR 0.00, N 0.21, R 0.32, HR 0.47\n",
      "Absolute (eval): IR 0.00, N 2.00, R 0.00, HR 0.00\n",
      "Relative (eval): IR 0.00, N 1.00, R 0.00, HR 0.00\n",
      "Role samples for SERVICER in train: 19, eval: 2, test: 57\n",
      "NDCG after 100x random order:\n",
      " > mean ndcg = 1.0 | std = 0.0\n",
      "NDCG for worst case (inverted best) order:\n",
      " > ndcg = 1.0\n",
      "Accuracy | role : 0.614035087719\n",
      "Accuracy | full : 0.649122807018\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " irrelevant       0.00      0.00      0.00         3\n",
      "    neutral       0.00      0.00      0.00         9\n",
      "   relevant       0.68      0.95      0.79        38\n",
      "     highly       0.25      0.14      0.18         7\n",
      "\n",
      "avg / total       0.48      0.65      0.55        57\n",
      "\n",
      "[[ 0  0  3  0]\n",
      " [ 0  0  8  1]\n",
      " [ 0  0 36  2]\n",
      " [ 0  0  6  1]]\n",
      "> NDCG Score | role | categ  | 0.87626\n",
      "> NDCG Score | role | proba* | 0.89953\n",
      "> NDCG Score | full | categ  | 0.87521\n",
      "> NDCG Score | full | proba* | 0.89387\n",
      "=== TRUSTEE ======\n",
      "Items in training set: 364 (86.67%)\n",
      "Items in eval set: 56\n",
      "Items in test set: 304\n",
      " = 724\n",
      "Number of source documents: 40 total, 18 train, 3 eval 19 test\n",
      "Absolute (training): IR 21.00, N 123.00, R 69.00, HR 151.00\n",
      "Relative (training): IR 0.06, N 0.34, R 0.19, HR 0.41\n",
      "Absolute (eval): IR 0.00, N 41.00, R 10.00, HR 5.00\n",
      "Relative (eval): IR 0.00, N 0.73, R 0.18, HR 0.09\n",
      "Role samples for TRUSTEE in train: 364, eval: 56, test: 304\n",
      "NDCG after 100x random order:\n",
      " > mean ndcg = 0.801725594849 | std = 0.0299338657\n",
      "NDCG for worst case (inverted best) order:\n",
      " > ndcg = 0.734223104054\n",
      "Accuracy | role : 0.509868421053\n",
      "Accuracy | full : 0.371710526316\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " irrelevant       0.00      0.00      0.00         9\n",
      "    neutral       0.13      0.28      0.18        47\n",
      "   relevant       0.00      0.00      0.00       124\n",
      "     highly       0.50      0.81      0.62       124\n",
      "\n",
      "avg / total       0.22      0.37      0.28       304\n",
      "\n",
      "[[  0   4   3   2]\n",
      " [  0  13   1  33]\n",
      " [  0  58   0  66]\n",
      " [  0  24   0 100]]\n",
      "> NDCG Score | role | categ  | 0.97357\n",
      "> NDCG Score | role | proba* | 0.98121\n",
      "> NDCG Score | full | categ  | 0.97618\n",
      "> NDCG Score | full | proba* | 0.97705\n",
      "=== ISSUER ======\n",
      "Items in training set: 111 (86.05%)\n",
      "Items in eval set: 18\n",
      "Items in test set: 98\n",
      " = 227\n",
      "Number of source documents: 46 total, 21 train, 3 eval 22 test\n",
      "Absolute (training): IR 28.00, N 41.00, R 25.00, HR 17.00\n",
      "Relative (training): IR 0.25, N 0.37, R 0.23, HR 0.15\n",
      "Absolute (eval): IR 4.00, N 4.00, R 5.00, HR 5.00\n",
      "Relative (eval): IR 0.22, N 0.22, R 0.28, HR 0.28\n",
      "Role samples for ISSUER in train: 111, eval: 18, test: 98\n",
      "NDCG after 100x random order:\n",
      " > mean ndcg = 0.781815064043 | std = 0.0775629252071\n",
      "NDCG for worst case (inverted best) order:\n",
      " > ndcg = 0.53888990203\n",
      "Accuracy | role : 0.275510204082\n",
      "Accuracy | full : 0.234693877551\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " irrelevant       0.00      0.00      0.00        21\n",
      "    neutral       0.12      0.04      0.06        27\n",
      "   relevant       0.26      0.78      0.39        27\n",
      "     highly       0.12      0.04      0.06        23\n",
      "\n",
      "avg / total       0.13      0.23      0.14        98\n",
      "\n",
      "[[ 0  0 18  3]\n",
      " [ 0  1 23  3]\n",
      " [ 0  5 21  1]\n",
      " [ 0  2 20  1]]\n",
      "> NDCG Score | role | categ  | 0.70812\n",
      "> NDCG Score | role | proba* | 0.90649\n",
      "> NDCG Score | full | categ  | 0.73440\n",
      "> NDCG Score | full | proba* | 0.83473\n",
      "=== UNDERWRITER ======\n",
      "Items in training set: 19 (90.48%)\n",
      "Items in eval set: 2\n",
      "Items in test set: 40\n",
      " = 61\n",
      "Number of source documents: 16 total, 6 train, 1 eval 9 test\n",
      "Absolute (training): IR 0.00, N 0.00, R 12.00, HR 7.00\n",
      "Relative (training): IR 0.00, N 0.00, R 0.63, HR 0.37\n",
      "Absolute (eval): IR 0.00, N 0.00, R 2.00, HR 0.00\n",
      "Relative (eval): IR 0.00, N 0.00, R 1.00, HR 0.00\n",
      "Role samples for UNDERWRITER in train: 19, eval: 2, test: 40\n",
      "NDCG after 100x random order:\n",
      " > mean ndcg = 1.0 | std = 0.0\n",
      "NDCG for worst case (inverted best) order:\n",
      " > ndcg = 1.0\n",
      "Accuracy | role : 0.375\n",
      "Accuracy | full : 0.225\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " irrelevant       0.00      0.00      0.00         3\n",
      "    neutral       0.12      1.00      0.21         2\n",
      "   relevant       0.29      0.33      0.31        15\n",
      "     highly       0.33      0.10      0.15        20\n",
      "\n",
      "avg / total       0.28      0.23      0.20        40\n",
      "\n",
      "[[ 0  1  2  0]\n",
      " [ 0  2  0  0]\n",
      " [ 0  6  5  4]\n",
      " [ 0  8 10  2]]\n",
      "> NDCG Score | role | categ  | 0.86908\n",
      "> NDCG Score | role | proba* | 0.95738\n",
      "> NDCG Score | full | categ  | 0.90802\n",
      "> NDCG Score | full | proba* | 0.88910\n",
      "=== SELLER ======\n",
      "Items in training set: 17 (85.00%)\n",
      "Items in eval set: 3\n",
      "Items in test set: 49\n",
      " = 69\n",
      "Number of source documents: 19 total, 9 train, 1 eval 9 test\n",
      "Absolute (training): IR 0.00, N 1.00, R 11.00, HR 5.00\n",
      "Relative (training): IR 0.00, N 0.06, R 0.65, HR 0.29\n",
      "Absolute (eval): IR 0.00, N 0.00, R 3.00, HR 0.00\n",
      "Relative (eval): IR 0.00, N 0.00, R 1.00, HR 0.00\n",
      "Role samples for SELLER in train: 17, eval: 3, test: 49\n",
      "NDCG after 100x random order:\n",
      " > mean ndcg = 1.0 | std = 0.0\n",
      "NDCG for worst case (inverted best) order:\n",
      " > ndcg = 1.0\n",
      "Accuracy | role : 0.34693877551\n",
      "Accuracy | full : 0.367346938776\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " irrelevant       0.00      0.00      0.00         4\n",
      "    neutral       0.17      0.10      0.12        10\n",
      "   relevant       0.31      0.59      0.41        17\n",
      "     highly       0.64      0.39      0.48        18\n",
      "\n",
      "avg / total       0.38      0.37      0.34        49\n",
      "\n",
      "[[ 0  0  4  0]\n",
      " [ 0  1  8  1]\n",
      " [ 0  4 10  3]\n",
      " [ 0  1 10  7]]\n",
      "> NDCG Score | role | categ  | 0.80424\n",
      "> NDCG Score | role | proba* | 0.84721\n",
      "> NDCG Score | full | categ  | 0.92306\n",
      "> NDCG Score | full | proba* | 0.92186\n",
      "=== AFFILIATE ======\n",
      "Items in training set: 175 (94.09%)\n",
      "Items in eval set: 11\n",
      "Items in test set: 129\n",
      " = 315\n",
      "Number of source documents: 41 total, 19 train, 3 eval 19 test\n",
      "Absolute (training): IR 26.00, N 37.00, R 55.00, HR 57.00\n",
      "Relative (training): IR 0.15, N 0.21, R 0.31, HR 0.33\n",
      "Absolute (eval): IR 0.00, N 3.00, R 7.00, HR 1.00\n",
      "Relative (eval): IR 0.00, N 0.27, R 0.64, HR 0.09\n",
      "Role samples for AFFILIATE in train: 175, eval: 11, test: 129\n",
      "NDCG after 100x random order:\n",
      " > mean ndcg = 0.89371983125 | std = 0.0442094344106\n",
      "NDCG for worst case (inverted best) order:\n",
      " > ndcg = 0.782113993817\n",
      "Accuracy | role : 0.53488372093\n",
      "Accuracy | full : 0.503875968992\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " irrelevant       0.00      0.00      0.00        17\n",
      "    neutral       0.00      0.00      0.00        12\n",
      "   relevant       0.49      0.83      0.62        54\n",
      "     highly       0.77      0.43      0.56        46\n",
      "\n",
      "avg / total       0.48      0.50      0.46       129\n",
      "\n",
      "[[ 0  0 17  0]\n",
      " [ 0  0 12  0]\n",
      " [ 0  3 45  6]\n",
      " [ 0  9 17 20]]\n",
      "> NDCG Score | role | categ  | 0.90089\n",
      "> NDCG Score | role | proba* | 0.94142\n",
      "> NDCG Score | full | categ  | 0.93981\n",
      "> NDCG Score | full | proba* | 0.95627\n",
      "TOTAL NDCG | role | categ  | 0.93856\n",
      "TOTAL NDCG | role | proba* | 0.94384\n",
      "TOTAL NDCG | full | categ  | 0.92916\n",
      "TOTAL NDCG | full | proba* | 0.94914\n",
      "baseline_rand 10\n",
      "baseline_worst 10\n",
      "ndcg_role 10\n",
      "ndcg_full 10\n",
      "ndcg_role_proba 10\n",
      "ndcg_full_proba 10\n",
      "acc_role 10\n",
      "acc_full 10\n",
      "f1_role 10\n",
      "f1_full 10\n"
     ]
    }
   ],
   "source": [
    "res, macro_res, conf_matrix_role, conf_matrix_full = kfold(5, data, pipeline, score_func, predict_on='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate trained classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_full</th>\n",
       "      <th>acc_role</th>\n",
       "      <th>baseline_rand</th>\n",
       "      <th>baseline_worst</th>\n",
       "      <th>f1_full</th>\n",
       "      <th>f1_role</th>\n",
       "      <th>ndcg_full</th>\n",
       "      <th>ndcg_full_proba</th>\n",
       "      <th>ndcg_role</th>\n",
       "      <th>ndcg_role_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.388052</td>\n",
       "      <td>0.406654</td>\n",
       "      <td>0.910372</td>\n",
       "      <td>0.818403</td>\n",
       "      <td>0.314622</td>\n",
       "      <td>0.280824</td>\n",
       "      <td>0.882182</td>\n",
       "      <td>0.878494</td>\n",
       "      <td>0.875601</td>\n",
       "      <td>0.901836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.138206</td>\n",
       "      <td>0.170997</td>\n",
       "      <td>0.103925</td>\n",
       "      <td>0.185720</td>\n",
       "      <td>0.151217</td>\n",
       "      <td>0.186599</td>\n",
       "      <td>0.063615</td>\n",
       "      <td>0.055747</td>\n",
       "      <td>0.056086</td>\n",
       "      <td>0.050273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.122807</td>\n",
       "      <td>0.612471</td>\n",
       "      <td>0.383845</td>\n",
       "      <td>0.119354</td>\n",
       "      <td>0.026864</td>\n",
       "      <td>0.702504</td>\n",
       "      <td>0.720749</td>\n",
       "      <td>0.708118</td>\n",
       "      <td>0.754071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.275000</td>\n",
       "      <td>0.343679</td>\n",
       "      <td>0.869483</td>\n",
       "      <td>0.716033</td>\n",
       "      <td>0.195506</td>\n",
       "      <td>0.178726</td>\n",
       "      <td>0.856819</td>\n",
       "      <td>0.853105</td>\n",
       "      <td>0.856627</td>\n",
       "      <td>0.870239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.367347</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.952526</td>\n",
       "      <td>0.888323</td>\n",
       "      <td>0.275120</td>\n",
       "      <td>0.204545</td>\n",
       "      <td>0.888248</td>\n",
       "      <td>0.882264</td>\n",
       "      <td>0.875147</td>\n",
       "      <td>0.898638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.426433</td>\n",
       "      <td>0.480263</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.429749</td>\n",
       "      <td>0.382138</td>\n",
       "      <td>0.919959</td>\n",
       "      <td>0.900386</td>\n",
       "      <td>0.896197</td>\n",
       "      <td>0.940617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.593651</td>\n",
       "      <td>0.691429</td>\n",
       "      <td>0.984343</td>\n",
       "      <td>0.977051</td>\n",
       "      <td>0.973650</td>\n",
       "      <td>0.981214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        acc_full   acc_role  baseline_rand  baseline_worst    f1_full  \\\n",
       "count  50.000000  50.000000      40.000000       40.000000  50.000000   \n",
       "mean    0.388052   0.406654       0.910372        0.818403   0.314622   \n",
       "std     0.138206   0.170997       0.103925        0.185720   0.151217   \n",
       "min     0.200000   0.122807       0.612471        0.383845   0.119354   \n",
       "25%     0.275000   0.343679       0.869483        0.716033   0.195506   \n",
       "50%     0.367347   0.375000       0.952526        0.888323   0.275120   \n",
       "75%     0.426433   0.480263       1.000000        1.000000   0.429749   \n",
       "max     0.684211   0.785714       1.000000        1.000000   0.593651   \n",
       "\n",
       "         f1_role  ndcg_full  ndcg_full_proba  ndcg_role  ndcg_role_proba  \n",
       "count  50.000000  50.000000        50.000000  50.000000        50.000000  \n",
       "mean    0.280824   0.882182         0.878494   0.875601         0.901836  \n",
       "std     0.186599   0.063615         0.055747   0.056086         0.050273  \n",
       "min     0.026864   0.702504         0.720749   0.708118         0.754071  \n",
       "25%     0.178726   0.856819         0.853105   0.856627         0.870239  \n",
       "50%     0.204545   0.888248         0.882264   0.875147         0.898638  \n",
       "75%     0.382138   0.919959         0.900386   0.896197         0.940617  \n",
       "max     0.691429   0.984343         0.977051   0.973650         0.981214  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(res).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>GUARANTOR</h2><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_full</th>\n",
       "      <th>acc_role</th>\n",
       "      <th>baseline_rand</th>\n",
       "      <th>baseline_worst</th>\n",
       "      <th>f1_full</th>\n",
       "      <th>f1_role</th>\n",
       "      <th>ndcg_full</th>\n",
       "      <th>ndcg_full_proba</th>\n",
       "      <th>ndcg_role</th>\n",
       "      <th>ndcg_role_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.510432</td>\n",
       "      <td>0.584211</td>\n",
       "      <td>0.978612</td>\n",
       "      <td>0.930979</td>\n",
       "      <td>0.526110</td>\n",
       "      <td>0.558939</td>\n",
       "      <td>0.950289</td>\n",
       "      <td>0.956642</td>\n",
       "      <td>0.930653</td>\n",
       "      <td>0.958371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.029253</td>\n",
       "      <td>0.134579</td>\n",
       "      <td>0.026210</td>\n",
       "      <td>0.061880</td>\n",
       "      <td>0.046023</td>\n",
       "      <td>0.144987</td>\n",
       "      <td>0.027016</td>\n",
       "      <td>0.033217</td>\n",
       "      <td>0.038142</td>\n",
       "      <td>0.028306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.450658</td>\n",
       "      <td>0.949374</td>\n",
       "      <td>0.880463</td>\n",
       "      <td>0.476768</td>\n",
       "      <td>0.409415</td>\n",
       "      <td>0.918337</td>\n",
       "      <td>0.918402</td>\n",
       "      <td>0.883185</td>\n",
       "      <td>0.917370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.506579</td>\n",
       "      <td>0.470395</td>\n",
       "      <td>0.967918</td>\n",
       "      <td>0.896469</td>\n",
       "      <td>0.494858</td>\n",
       "      <td>0.413077</td>\n",
       "      <td>0.929329</td>\n",
       "      <td>0.928040</td>\n",
       "      <td>0.915258</td>\n",
       "      <td>0.952020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.509868</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.986461</td>\n",
       "      <td>0.912476</td>\n",
       "      <td>0.509369</td>\n",
       "      <td>0.613874</td>\n",
       "      <td>0.949208</td>\n",
       "      <td>0.958216</td>\n",
       "      <td>0.915258</td>\n",
       "      <td>0.952020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.993230</td>\n",
       "      <td>0.956238</td>\n",
       "      <td>0.570114</td>\n",
       "      <td>0.613874</td>\n",
       "      <td>0.976858</td>\n",
       "      <td>0.988770</td>\n",
       "      <td>0.965901</td>\n",
       "      <td>0.984420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.579443</td>\n",
       "      <td>0.744454</td>\n",
       "      <td>0.977715</td>\n",
       "      <td>0.989785</td>\n",
       "      <td>0.973659</td>\n",
       "      <td>0.986023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><h2>AGENT</h2><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_full</th>\n",
       "      <th>acc_role</th>\n",
       "      <th>baseline_rand</th>\n",
       "      <th>baseline_worst</th>\n",
       "      <th>f1_full</th>\n",
       "      <th>f1_role</th>\n",
       "      <th>ndcg_full</th>\n",
       "      <th>ndcg_full_proba</th>\n",
       "      <th>ndcg_role</th>\n",
       "      <th>ndcg_role_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.351735</td>\n",
       "      <td>0.337857</td>\n",
       "      <td>0.826983</td>\n",
       "      <td>0.693615</td>\n",
       "      <td>0.325255</td>\n",
       "      <td>0.280731</td>\n",
       "      <td>0.887430</td>\n",
       "      <td>0.899829</td>\n",
       "      <td>0.854907</td>\n",
       "      <td>0.817587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.038063</td>\n",
       "      <td>0.025971</td>\n",
       "      <td>0.154868</td>\n",
       "      <td>0.263551</td>\n",
       "      <td>0.050513</td>\n",
       "      <td>0.048229</td>\n",
       "      <td>0.030689</td>\n",
       "      <td>0.048807</td>\n",
       "      <td>0.029679</td>\n",
       "      <td>0.019390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.623685</td>\n",
       "      <td>0.383845</td>\n",
       "      <td>0.244661</td>\n",
       "      <td>0.235152</td>\n",
       "      <td>0.852522</td>\n",
       "      <td>0.839463</td>\n",
       "      <td>0.829634</td>\n",
       "      <td>0.802632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.336735</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>0.725869</td>\n",
       "      <td>0.505517</td>\n",
       "      <td>0.321562</td>\n",
       "      <td>0.241477</td>\n",
       "      <td>0.864829</td>\n",
       "      <td>0.858578</td>\n",
       "      <td>0.832354</td>\n",
       "      <td>0.807892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.346939</td>\n",
       "      <td>0.346939</td>\n",
       "      <td>0.838757</td>\n",
       "      <td>0.658411</td>\n",
       "      <td>0.327992</td>\n",
       "      <td>0.265105</td>\n",
       "      <td>0.881639</td>\n",
       "      <td>0.913175</td>\n",
       "      <td>0.845152</td>\n",
       "      <td>0.812580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.946603</td>\n",
       "      <td>0.920303</td>\n",
       "      <td>0.352532</td>\n",
       "      <td>0.316897</td>\n",
       "      <td>0.918386</td>\n",
       "      <td>0.936590</td>\n",
       "      <td>0.866047</td>\n",
       "      <td>0.813422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.367347</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.379529</td>\n",
       "      <td>0.345024</td>\n",
       "      <td>0.919772</td>\n",
       "      <td>0.951341</td>\n",
       "      <td>0.901347</td>\n",
       "      <td>0.851407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><h2>COUNTERPART</h2><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_full</th>\n",
       "      <th>acc_role</th>\n",
       "      <th>baseline_rand</th>\n",
       "      <th>baseline_worst</th>\n",
       "      <th>f1_full</th>\n",
       "      <th>f1_role</th>\n",
       "      <th>ndcg_full</th>\n",
       "      <th>ndcg_full_proba</th>\n",
       "      <th>ndcg_role</th>\n",
       "      <th>ndcg_role_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.482222</td>\n",
       "      <td>0.404259</td>\n",
       "      <td>0.947960</td>\n",
       "      <td>0.874404</td>\n",
       "      <td>0.451274</td>\n",
       "      <td>0.358148</td>\n",
       "      <td>0.936145</td>\n",
       "      <td>0.938098</td>\n",
       "      <td>0.934071</td>\n",
       "      <td>0.876913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.153718</td>\n",
       "      <td>0.078801</td>\n",
       "      <td>0.044311</td>\n",
       "      <td>0.157329</td>\n",
       "      <td>0.151770</td>\n",
       "      <td>0.049028</td>\n",
       "      <td>0.033435</td>\n",
       "      <td>0.037565</td>\n",
       "      <td>0.021505</td>\n",
       "      <td>0.049408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.351852</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.892491</td>\n",
       "      <td>0.644311</td>\n",
       "      <td>0.320405</td>\n",
       "      <td>0.307526</td>\n",
       "      <td>0.896250</td>\n",
       "      <td>0.882252</td>\n",
       "      <td>0.902650</td>\n",
       "      <td>0.798679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.930086</td>\n",
       "      <td>0.851305</td>\n",
       "      <td>0.344503</td>\n",
       "      <td>0.316660</td>\n",
       "      <td>0.920129</td>\n",
       "      <td>0.921944</td>\n",
       "      <td>0.929849</td>\n",
       "      <td>0.860455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.379630</td>\n",
       "      <td>0.949675</td>\n",
       "      <td>0.926653</td>\n",
       "      <td>0.357697</td>\n",
       "      <td>0.354300</td>\n",
       "      <td>0.922378</td>\n",
       "      <td>0.943618</td>\n",
       "      <td>0.934757</td>\n",
       "      <td>0.893189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.967549</td>\n",
       "      <td>0.949753</td>\n",
       "      <td>0.616117</td>\n",
       "      <td>0.387255</td>\n",
       "      <td>0.969206</td>\n",
       "      <td>0.967841</td>\n",
       "      <td>0.940752</td>\n",
       "      <td>0.912013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.972763</td>\n",
       "      <td>0.974835</td>\n",
       "      <td>0.962349</td>\n",
       "      <td>0.920231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><h2>INSURER</h2><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_full</th>\n",
       "      <th>acc_role</th>\n",
       "      <th>baseline_rand</th>\n",
       "      <th>baseline_worst</th>\n",
       "      <th>f1_full</th>\n",
       "      <th>f1_role</th>\n",
       "      <th>ndcg_full</th>\n",
       "      <th>ndcg_full_proba</th>\n",
       "      <th>ndcg_role</th>\n",
       "      <th>ndcg_role_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.573600</td>\n",
       "      <td>0.487364</td>\n",
       "      <td>0.969429</td>\n",
       "      <td>0.910701</td>\n",
       "      <td>0.541295</td>\n",
       "      <td>0.416642</td>\n",
       "      <td>0.940360</td>\n",
       "      <td>0.969815</td>\n",
       "      <td>0.875326</td>\n",
       "      <td>0.904650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.042261</td>\n",
       "      <td>0.149152</td>\n",
       "      <td>0.052951</td>\n",
       "      <td>0.154671</td>\n",
       "      <td>0.048147</td>\n",
       "      <td>0.183457</td>\n",
       "      <td>0.041082</td>\n",
       "      <td>0.024648</td>\n",
       "      <td>0.062873</td>\n",
       "      <td>0.050412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.510204</td>\n",
       "      <td>0.346939</td>\n",
       "      <td>0.908286</td>\n",
       "      <td>0.732103</td>\n",
       "      <td>0.470021</td>\n",
       "      <td>0.232753</td>\n",
       "      <td>0.878543</td>\n",
       "      <td>0.931919</td>\n",
       "      <td>0.779235</td>\n",
       "      <td>0.832916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.553191</td>\n",
       "      <td>0.387755</td>\n",
       "      <td>0.954143</td>\n",
       "      <td>0.866051</td>\n",
       "      <td>0.517587</td>\n",
       "      <td>0.288533</td>\n",
       "      <td>0.917993</td>\n",
       "      <td>0.957685</td>\n",
       "      <td>0.847127</td>\n",
       "      <td>0.870231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.591837</td>\n",
       "      <td>0.404255</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.553309</td>\n",
       "      <td>0.334890</td>\n",
       "      <td>0.962943</td>\n",
       "      <td>0.983603</td>\n",
       "      <td>0.896197</td>\n",
       "      <td>0.933217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.595745</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.578084</td>\n",
       "      <td>0.603620</td>\n",
       "      <td>0.967830</td>\n",
       "      <td>0.987585</td>\n",
       "      <td>0.926781</td>\n",
       "      <td>0.941299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.659574</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.587477</td>\n",
       "      <td>0.623413</td>\n",
       "      <td>0.974488</td>\n",
       "      <td>0.988281</td>\n",
       "      <td>0.927289</td>\n",
       "      <td>0.945586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><h2>SERVICER</h2><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_full</th>\n",
       "      <th>acc_role</th>\n",
       "      <th>baseline_rand</th>\n",
       "      <th>baseline_worst</th>\n",
       "      <th>f1_full</th>\n",
       "      <th>f1_role</th>\n",
       "      <th>ndcg_full</th>\n",
       "      <th>ndcg_full_proba</th>\n",
       "      <th>ndcg_role</th>\n",
       "      <th>ndcg_role_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.386291</td>\n",
       "      <td>0.332191</td>\n",
       "      <td>0.902965</td>\n",
       "      <td>0.769861</td>\n",
       "      <td>0.390879</td>\n",
       "      <td>0.314099</td>\n",
       "      <td>0.913972</td>\n",
       "      <td>0.928395</td>\n",
       "      <td>0.902573</td>\n",
       "      <td>0.919213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.132419</td>\n",
       "      <td>0.143518</td>\n",
       "      <td>0.074687</td>\n",
       "      <td>0.156946</td>\n",
       "      <td>0.105104</td>\n",
       "      <td>0.170753</td>\n",
       "      <td>0.029434</td>\n",
       "      <td>0.049143</td>\n",
       "      <td>0.039099</td>\n",
       "      <td>0.065662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.245614</td>\n",
       "      <td>0.228070</td>\n",
       "      <td>0.821856</td>\n",
       "      <td>0.599097</td>\n",
       "      <td>0.263535</td>\n",
       "      <td>0.164926</td>\n",
       "      <td>0.870240</td>\n",
       "      <td>0.889699</td>\n",
       "      <td>0.863322</td>\n",
       "      <td>0.826561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.298246</td>\n",
       "      <td>0.228070</td>\n",
       "      <td>0.869997</td>\n",
       "      <td>0.700893</td>\n",
       "      <td>0.339063</td>\n",
       "      <td>0.164926</td>\n",
       "      <td>0.907217</td>\n",
       "      <td>0.890635</td>\n",
       "      <td>0.880250</td>\n",
       "      <td>0.902051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.228070</td>\n",
       "      <td>0.918139</td>\n",
       "      <td>0.802690</td>\n",
       "      <td>0.353230</td>\n",
       "      <td>0.247485</td>\n",
       "      <td>0.910684</td>\n",
       "      <td>0.897455</td>\n",
       "      <td>0.880250</td>\n",
       "      <td>0.902051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.519380</td>\n",
       "      <td>0.465116</td>\n",
       "      <td>0.943519</td>\n",
       "      <td>0.855243</td>\n",
       "      <td>0.485767</td>\n",
       "      <td>0.473263</td>\n",
       "      <td>0.935819</td>\n",
       "      <td>0.979580</td>\n",
       "      <td>0.939116</td>\n",
       "      <td>0.980343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.534884</td>\n",
       "      <td>0.511628</td>\n",
       "      <td>0.968900</td>\n",
       "      <td>0.907796</td>\n",
       "      <td>0.512802</td>\n",
       "      <td>0.519893</td>\n",
       "      <td>0.945897</td>\n",
       "      <td>0.984606</td>\n",
       "      <td>0.949926</td>\n",
       "      <td>0.985057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><h2>TRUSTEE</h2><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_full</th>\n",
       "      <th>acc_role</th>\n",
       "      <th>baseline_rand</th>\n",
       "      <th>baseline_worst</th>\n",
       "      <th>f1_full</th>\n",
       "      <th>f1_role</th>\n",
       "      <th>ndcg_full</th>\n",
       "      <th>ndcg_full_proba</th>\n",
       "      <th>ndcg_role</th>\n",
       "      <th>ndcg_role_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.505921</td>\n",
       "      <td>0.521147</td>\n",
       "      <td>0.985716</td>\n",
       "      <td>0.913860</td>\n",
       "      <td>0.515672</td>\n",
       "      <td>0.504801</td>\n",
       "      <td>0.961502</td>\n",
       "      <td>0.968431</td>\n",
       "      <td>0.949590</td>\n",
       "      <td>0.971538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.025930</td>\n",
       "      <td>0.078916</td>\n",
       "      <td>0.014670</td>\n",
       "      <td>0.085456</td>\n",
       "      <td>0.035653</td>\n",
       "      <td>0.102797</td>\n",
       "      <td>0.027766</td>\n",
       "      <td>0.030907</td>\n",
       "      <td>0.031633</td>\n",
       "      <td>0.017846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.450658</td>\n",
       "      <td>0.970687</td>\n",
       "      <td>0.829105</td>\n",
       "      <td>0.476768</td>\n",
       "      <td>0.409415</td>\n",
       "      <td>0.918337</td>\n",
       "      <td>0.918402</td>\n",
       "      <td>0.915258</td>\n",
       "      <td>0.952020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.506579</td>\n",
       "      <td>0.470395</td>\n",
       "      <td>0.978574</td>\n",
       "      <td>0.870790</td>\n",
       "      <td>0.494858</td>\n",
       "      <td>0.413077</td>\n",
       "      <td>0.949208</td>\n",
       "      <td>0.958216</td>\n",
       "      <td>0.915258</td>\n",
       "      <td>0.952020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.509868</td>\n",
       "      <td>0.470395</td>\n",
       "      <td>0.986461</td>\n",
       "      <td>0.912476</td>\n",
       "      <td>0.509369</td>\n",
       "      <td>0.473765</td>\n",
       "      <td>0.976858</td>\n",
       "      <td>0.986980</td>\n",
       "      <td>0.965901</td>\n",
       "      <td>0.983207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.513158</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.993230</td>\n",
       "      <td>0.956238</td>\n",
       "      <td>0.527251</td>\n",
       "      <td>0.613874</td>\n",
       "      <td>0.977715</td>\n",
       "      <td>0.988770</td>\n",
       "      <td>0.973659</td>\n",
       "      <td>0.984420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.570114</td>\n",
       "      <td>0.613874</td>\n",
       "      <td>0.985393</td>\n",
       "      <td>0.989785</td>\n",
       "      <td>0.977871</td>\n",
       "      <td>0.986023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><h2>ISSUER</h2><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_full</th>\n",
       "      <th>acc_role</th>\n",
       "      <th>baseline_rand</th>\n",
       "      <th>baseline_worst</th>\n",
       "      <th>f1_full</th>\n",
       "      <th>f1_role</th>\n",
       "      <th>ndcg_full</th>\n",
       "      <th>ndcg_full_proba</th>\n",
       "      <th>ndcg_role</th>\n",
       "      <th>ndcg_role_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.356327</td>\n",
       "      <td>0.346327</td>\n",
       "      <td>0.775063</td>\n",
       "      <td>0.592343</td>\n",
       "      <td>0.329493</td>\n",
       "      <td>0.301594</td>\n",
       "      <td>0.874011</td>\n",
       "      <td>0.886757</td>\n",
       "      <td>0.847732</td>\n",
       "      <td>0.820823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.042677</td>\n",
       "      <td>0.027585</td>\n",
       "      <td>0.122495</td>\n",
       "      <td>0.207771</td>\n",
       "      <td>0.054133</td>\n",
       "      <td>0.049547</td>\n",
       "      <td>0.028348</td>\n",
       "      <td>0.039410</td>\n",
       "      <td>0.017471</td>\n",
       "      <td>0.017531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.623685</td>\n",
       "      <td>0.383845</td>\n",
       "      <td>0.244661</td>\n",
       "      <td>0.235152</td>\n",
       "      <td>0.851293</td>\n",
       "      <td>0.839463</td>\n",
       "      <td>0.829634</td>\n",
       "      <td>0.807892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.336735</td>\n",
       "      <td>0.346939</td>\n",
       "      <td>0.725869</td>\n",
       "      <td>0.493639</td>\n",
       "      <td>0.321562</td>\n",
       "      <td>0.265105</td>\n",
       "      <td>0.852522</td>\n",
       "      <td>0.858578</td>\n",
       "      <td>0.832354</td>\n",
       "      <td>0.812580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.346939</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.740400</td>\n",
       "      <td>0.505517</td>\n",
       "      <td>0.327992</td>\n",
       "      <td>0.316897</td>\n",
       "      <td>0.864829</td>\n",
       "      <td>0.885977</td>\n",
       "      <td>0.845152</td>\n",
       "      <td>0.813422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.367347</td>\n",
       "      <td>0.838757</td>\n",
       "      <td>0.658411</td>\n",
       "      <td>0.373724</td>\n",
       "      <td>0.345024</td>\n",
       "      <td>0.881639</td>\n",
       "      <td>0.913175</td>\n",
       "      <td>0.865475</td>\n",
       "      <td>0.818814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.367347</td>\n",
       "      <td>0.946603</td>\n",
       "      <td>0.920303</td>\n",
       "      <td>0.379529</td>\n",
       "      <td>0.345790</td>\n",
       "      <td>0.919772</td>\n",
       "      <td>0.936590</td>\n",
       "      <td>0.866047</td>\n",
       "      <td>0.851407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><h2>UNDERWRITER</h2><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_full</th>\n",
       "      <th>acc_role</th>\n",
       "      <th>baseline_rand</th>\n",
       "      <th>baseline_worst</th>\n",
       "      <th>f1_full</th>\n",
       "      <th>f1_role</th>\n",
       "      <th>ndcg_full</th>\n",
       "      <th>ndcg_full_proba</th>\n",
       "      <th>ndcg_role</th>\n",
       "      <th>ndcg_role_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.519444</td>\n",
       "      <td>0.408333</td>\n",
       "      <td>0.962306</td>\n",
       "      <td>0.894329</td>\n",
       "      <td>0.489531</td>\n",
       "      <td>0.338479</td>\n",
       "      <td>0.948329</td>\n",
       "      <td>0.944239</td>\n",
       "      <td>0.934714</td>\n",
       "      <td>0.869570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.147890</td>\n",
       "      <td>0.077728</td>\n",
       "      <td>0.050816</td>\n",
       "      <td>0.169644</td>\n",
       "      <td>0.146295</td>\n",
       "      <td>0.067286</td>\n",
       "      <td>0.037044</td>\n",
       "      <td>0.041041</td>\n",
       "      <td>0.020347</td>\n",
       "      <td>0.049112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.351852</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.892491</td>\n",
       "      <td>0.644311</td>\n",
       "      <td>0.320405</td>\n",
       "      <td>0.255952</td>\n",
       "      <td>0.896250</td>\n",
       "      <td>0.882252</td>\n",
       "      <td>0.905865</td>\n",
       "      <td>0.798679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.940672</td>\n",
       "      <td>0.860830</td>\n",
       "      <td>0.344503</td>\n",
       "      <td>0.307526</td>\n",
       "      <td>0.922378</td>\n",
       "      <td>0.921944</td>\n",
       "      <td>0.929849</td>\n",
       "      <td>0.856474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.978366</td>\n",
       "      <td>0.966502</td>\n",
       "      <td>0.548981</td>\n",
       "      <td>0.316660</td>\n",
       "      <td>0.969206</td>\n",
       "      <td>0.967841</td>\n",
       "      <td>0.934757</td>\n",
       "      <td>0.860455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.616117</td>\n",
       "      <td>0.387255</td>\n",
       "      <td>0.972763</td>\n",
       "      <td>0.974321</td>\n",
       "      <td>0.940752</td>\n",
       "      <td>0.912013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.981047</td>\n",
       "      <td>0.974835</td>\n",
       "      <td>0.962349</td>\n",
       "      <td>0.920231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><h2>SELLER</h2><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_full</th>\n",
       "      <th>acc_role</th>\n",
       "      <th>baseline_rand</th>\n",
       "      <th>baseline_worst</th>\n",
       "      <th>f1_full</th>\n",
       "      <th>f1_role</th>\n",
       "      <th>ndcg_full</th>\n",
       "      <th>ndcg_full_proba</th>\n",
       "      <th>ndcg_role</th>\n",
       "      <th>ndcg_role_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.556492</td>\n",
       "      <td>0.396266</td>\n",
       "      <td>0.942157</td>\n",
       "      <td>0.861405</td>\n",
       "      <td>0.525392</td>\n",
       "      <td>0.321261</td>\n",
       "      <td>0.956183</td>\n",
       "      <td>0.960382</td>\n",
       "      <td>0.852433</td>\n",
       "      <td>0.892779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.047982</td>\n",
       "      <td>0.156592</td>\n",
       "      <td>0.050337</td>\n",
       "      <td>0.134190</td>\n",
       "      <td>0.046044</td>\n",
       "      <td>0.172740</td>\n",
       "      <td>0.022232</td>\n",
       "      <td>0.025166</td>\n",
       "      <td>0.059996</td>\n",
       "      <td>0.045067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.510204</td>\n",
       "      <td>0.204082</td>\n",
       "      <td>0.908286</td>\n",
       "      <td>0.732103</td>\n",
       "      <td>0.470021</td>\n",
       "      <td>0.146507</td>\n",
       "      <td>0.917993</td>\n",
       "      <td>0.931919</td>\n",
       "      <td>0.779235</td>\n",
       "      <td>0.832916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.510204</td>\n",
       "      <td>0.346939</td>\n",
       "      <td>0.913236</td>\n",
       "      <td>0.792107</td>\n",
       "      <td>0.498568</td>\n",
       "      <td>0.232753</td>\n",
       "      <td>0.957662</td>\n",
       "      <td>0.940421</td>\n",
       "      <td>0.812822</td>\n",
       "      <td>0.870231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.553191</td>\n",
       "      <td>0.387755</td>\n",
       "      <td>0.918186</td>\n",
       "      <td>0.852112</td>\n",
       "      <td>0.517587</td>\n",
       "      <td>0.288533</td>\n",
       "      <td>0.962943</td>\n",
       "      <td>0.957685</td>\n",
       "      <td>0.847127</td>\n",
       "      <td>0.886233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.591837</td>\n",
       "      <td>0.404255</td>\n",
       "      <td>0.959093</td>\n",
       "      <td>0.926056</td>\n",
       "      <td>0.553309</td>\n",
       "      <td>0.334890</td>\n",
       "      <td>0.967830</td>\n",
       "      <td>0.983603</td>\n",
       "      <td>0.896197</td>\n",
       "      <td>0.933217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.587477</td>\n",
       "      <td>0.603620</td>\n",
       "      <td>0.974488</td>\n",
       "      <td>0.988281</td>\n",
       "      <td>0.926781</td>\n",
       "      <td>0.941299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><h2>AFFILIATE</h2><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_full</th>\n",
       "      <th>acc_role</th>\n",
       "      <th>baseline_rand</th>\n",
       "      <th>baseline_worst</th>\n",
       "      <th>f1_full</th>\n",
       "      <th>f1_role</th>\n",
       "      <th>ndcg_full</th>\n",
       "      <th>ndcg_full_proba</th>\n",
       "      <th>ndcg_role</th>\n",
       "      <th>ndcg_role_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.451897</td>\n",
       "      <td>0.399755</td>\n",
       "      <td>0.901540</td>\n",
       "      <td>0.744352</td>\n",
       "      <td>0.446744</td>\n",
       "      <td>0.391422</td>\n",
       "      <td>0.925182</td>\n",
       "      <td>0.940105</td>\n",
       "      <td>0.913516</td>\n",
       "      <td>0.931815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.126421</td>\n",
       "      <td>0.160733</td>\n",
       "      <td>0.061048</td>\n",
       "      <td>0.137928</td>\n",
       "      <td>0.094160</td>\n",
       "      <td>0.173824</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>0.046849</td>\n",
       "      <td>0.038946</td>\n",
       "      <td>0.067564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.298246</td>\n",
       "      <td>0.228070</td>\n",
       "      <td>0.821856</td>\n",
       "      <td>0.599097</td>\n",
       "      <td>0.339063</td>\n",
       "      <td>0.164926</td>\n",
       "      <td>0.870240</td>\n",
       "      <td>0.889699</td>\n",
       "      <td>0.863322</td>\n",
       "      <td>0.826561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.228070</td>\n",
       "      <td>0.878412</td>\n",
       "      <td>0.650644</td>\n",
       "      <td>0.353230</td>\n",
       "      <td>0.247485</td>\n",
       "      <td>0.910684</td>\n",
       "      <td>0.890635</td>\n",
       "      <td>0.880250</td>\n",
       "      <td>0.902051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.519380</td>\n",
       "      <td>0.465116</td>\n",
       "      <td>0.907701</td>\n",
       "      <td>0.735258</td>\n",
       "      <td>0.485767</td>\n",
       "      <td>0.473263</td>\n",
       "      <td>0.935819</td>\n",
       "      <td>0.956007</td>\n",
       "      <td>0.934967</td>\n",
       "      <td>0.965061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.534884</td>\n",
       "      <td>0.511628</td>\n",
       "      <td>0.930829</td>\n",
       "      <td>0.828966</td>\n",
       "      <td>0.512802</td>\n",
       "      <td>0.519893</td>\n",
       "      <td>0.945897</td>\n",
       "      <td>0.979580</td>\n",
       "      <td>0.939116</td>\n",
       "      <td>0.980343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.573643</td>\n",
       "      <td>0.565891</td>\n",
       "      <td>0.968900</td>\n",
       "      <td>0.907796</td>\n",
       "      <td>0.542858</td>\n",
       "      <td>0.551544</td>\n",
       "      <td>0.963268</td>\n",
       "      <td>0.984606</td>\n",
       "      <td>0.949926</td>\n",
       "      <td>0.985057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = \"\"\n",
    "for ir, r in enumerate(data.get_roles()):\n",
    "    out+=\"<h2>\"+r.upper()+\"</h2>\"\n",
    "    out+=pd.DataFrame(res).iloc[[ir+(ii*5) for ii in range(5)]].describe().to_html()\n",
    "HTML(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f6d6e973ac8>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAE0CAYAAADJxUOPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmVmNOcibmdWYg7yZWY05yJuZ1dj/A+pLQKFgOoqAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6cfc524d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "pd.DataFrame(res)[['baseline_worst','baseline_rand','ndcg_full','ndcg_role','ndcg_full_proba','ndcg_role_proba']]\\\n",
    "    .boxplot(figsize=(5,8), rot=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjgAAAEECAYAAAAlJU69AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFHBERETEdxRwRERExHcUcERERMR3/h/T4bal/Y0/bwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fde84a1b6d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm as colm\n",
    "plt.figure(figsize=(8,5))\n",
    "sub = plt.subplot(121)\n",
    "normed = conf_matrix_full/conf_matrix_full.sum()\n",
    "plt.imshow(normed, cmap=colm.Blues, vmax=0.5)\n",
    "plt.title('conf matrix FULL')\n",
    "sub.set_yticks([0,1,2,3])\n",
    "sub.set_yticklabels(['irrelevant', 'neutral','relevant', 'highly'])\n",
    "sub.set_xticks([0,1,2,3])\n",
    "sub.set_xticklabels(['irrelevant', 'neutral','relevant', 'highly'])\n",
    "\n",
    "for i in range(normed.shape[0]):\n",
    "    for j in range(normed.shape[1]):\n",
    "        v = normed.T[i][j]\n",
    "        c='%.2f'%v if v>0.005 else ''\n",
    "        sub.text(i, j, c, va='center', ha='center')\n",
    "\n",
    "\n",
    "\n",
    "sub = plt.subplot(122)\n",
    "normed = conf_matrix_role/conf_matrix_role.sum()\n",
    "plt.imshow(normed, cmap=colm.Blues, vmax=0.5)\n",
    "sub.yaxis.tick_right()\n",
    "sub.set_yticks([0,1,2,3])\n",
    "sub.set_yticklabels(['irrelevant', 'neutral','relevant', 'highly'])\n",
    "sub.set_xticks([0,1,2,3])\n",
    "sub.set_xticklabels(['irrelevant', 'neutral','relevant', 'highly'])\n",
    "\n",
    "for i in range(normed.shape[0]):\n",
    "    for j in range(normed.shape[1]):\n",
    "        v = normed.T[i][j]\n",
    "        c='%.2f'%v if v>0.01 else ''\n",
    "        sub.text(i, j, c, va='center', ha='center')\n",
    "        \n",
    "plt.title('conf matrix ROLE')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "affiliate 129\n",
      "agent 40\n",
      "counterpart 108\n",
      "guarantor 28\n",
      "insurer 47\n",
      "issuer 98\n",
      "seller 49\n",
      "servicer 57\n",
      "trustee 304\n",
      "underwriter 40\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([<matplotlib.axes._subplots.AxesSubplot object at 0x7fde73627f98>], dtype=object)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6gAAAF1CAYAAADlfsfwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fde77d6c978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "def score_func(x, norm=True):\n",
    "    kind = 'mulmax'\n",
    "    if kind=='last':\n",
    "        xx = x[-1]\n",
    "    elif kind=='mulmax':\n",
    "        xx = x.argmax(axis=1)*x.max(axis=1)\n",
    "    elif kind=='maxadjust':\n",
    "        xx = np.array([ai-xi[ai:ai+1].sum()+xi[ai+1:].sum() for xi,ai in zip(x,x.argmax(axis=1))])\n",
    "    elif kind == '1234':\n",
    "        xx = np.sum(x * np.array([1, 2, 3, 4]), axis=1)\n",
    "    elif kind == '1246':\n",
    "        xx = np.sum(x * np.array([1, 2, 4, 6]), axis=1)\n",
    "    elif kind=='1245':\n",
    "        xx = np.sum(x * np.array([1, 2, 4, 5]), axis=1)\n",
    "    else:\n",
    "        raise AttributeError('meh.')\n",
    "        \n",
    "    return (xx-xx.min())/(xx-xx.min()).max()\n",
    "\n",
    "distribution_full = []\n",
    "distribution_role = []\n",
    "scores_full = []\n",
    "scores_role = []\n",
    "\n",
    "scored_full = []\n",
    "scored_role = []\n",
    "\n",
    "for role, frm in data.test.groupby('grp'):\n",
    "    print(role, len(frm))\n",
    "    fmpred, fmppred = fm.predict(frm)\n",
    "    mpred, mppred = m[role].predict(frm)\n",
    "    \n",
    "    tmp = frm.copy()\n",
    "    tmp['SCORE'] = score_func(fmppred)\n",
    "    scored_full.append(tmp)\n",
    "    \n",
    "    tmp = frm.copy()\n",
    "    tmp['SCORE'] = score_func(mppred)\n",
    "    scored_role.append(tmp)\n",
    "    \n",
    "    distribution_full += list(fmpred)\n",
    "    distribution_role += list(mpred)\n",
    "    scores_full += list(score_func(fmppred))\n",
    "    scores_role += list(score_func(mppred))\n",
    "    \n",
    "classifier = 'bow'\n",
    "cols = ['SCORE', 'UNIQUE_ID', 'DOCUMENT_TYPE', 'FILER_NAME', 'FILER_CIK', 'FILING_INTERVAL', 'FILING_DATE', \n",
    "        'MENTIONED_FINANCIAL_ENTITY', 'ROLE', 'THREE_SENTENCES']\n",
    "\n",
    "pd.concat(scored_full).sort_values(by=['grp', 'SCORE'], \n",
    "                                   ascending=[True, False])[cols].to_csv('scored_full_'+classifier+'.csv',\n",
    "                                                                         index=False)\n",
    "pd.concat(scored_role).sort_values(by=['grp', 'SCORE'], \n",
    "                                   ascending=[True, False])[cols].to_csv('scored_role_'+classifier+'.csv',\n",
    "                                                                         index=False)\n",
    "\n",
    "\n",
    "f, ax = plt.subplots(figsize=(16,6), nrows=2, ncols=2)\n",
    "pd.DataFrame({'full_score':scores_full}).hist(ax=ax[0][0])\n",
    "pd.DataFrame({'full_argmax':distribution_full}).hist(ax=ax[0][1])\n",
    "pd.DataFrame({'role_score':scores_role}).hist(ax=ax[1][0])\n",
    "pd.DataFrame({'role_argmax':distribution_role}).hist(ax=ax[1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment with scoring functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7AAAAF1CAYAAADRBwbsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwEqSJEmSWuH/AOQehma4/r1rAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fde6e94fac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.522213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.221250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.384295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.489785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.698920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             test\n",
       "count  900.000000\n",
       "mean     0.522213\n",
       "std      0.221250\n",
       "min      0.000000\n",
       "25%      0.384295\n",
       "50%      0.489785\n",
       "75%      0.698920\n",
       "max      1.000000"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "def score_func(x, norm=True):\n",
    "    #return x.argmax(axis=1)\n",
    "    #return np.sum(x * (np.ones_like(x)+ x.argmax(axis=1)), axis=1)\n",
    "    #xx = ((x.argmax(axis=1))*x.argmax(axis=1)*x.max(axis=1))\n",
    "    #xx= np.array([ai-xi[ai:ai+1].sum()+xi[ai+1:].sum() for xi,ai in zip(x,a)])\n",
    "    #xx = x.argmax(axis=1)+x.max(axis=1)\n",
    "    #xx = x.argmax(axis=1)*x.max(axis=1)*x.max(axis=1)\n",
    "    #return xx\n",
    "    kind = 'mulmax'\n",
    "    if kind=='last':\n",
    "        xx = x[-1]\n",
    "    elif kind=='mulmax':\n",
    "        xx = x.argmax(axis=1)*x.max(axis=1)\n",
    "    elif kind=='maxadjust':\n",
    "        xx = np.array([ai-xi[ai:ai+1].sum()+xi[ai+1:].sum() for xi,ai in zip(x,x.argmax(axis=1))])\n",
    "    elif kind == '1234':\n",
    "        xx = np.sum(x * np.array([1, 2, 3, 4]), axis=1)\n",
    "    elif kind == '1246':\n",
    "        xx = np.sum(x * np.array([1, 2, 4, 6]), axis=1)\n",
    "    elif kind=='1245':\n",
    "        xx = np.sum(x * np.array([1, 2, 4, 5]), axis=1)\n",
    "    else:\n",
    "        raise AttributeError('meh.')\n",
    "        \n",
    "    return (xx-xx.min())/(xx-xx.min()).max()\n",
    "\n",
    "#pred, ppred = fm.predict(data.test)\n",
    "#epred, eppred = fm.predict(data.eval)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(16,6), nrows=2, ncols=3)\n",
    "pd.DataFrame({'test_score':score_func(ppred)}).hist(ax=ax[0][0])\n",
    "pd.DataFrame({'test_argmax':pred}).hist(ax=ax[0][1])\n",
    "pd.DataFrame({'eval_true':data.get_target(frm='eval')}).hist(ax=ax[1][2])\n",
    "pd.DataFrame({'eval_score':score_func(eppred)}).hist(ax=ax[1][0])\n",
    "pd.DataFrame({'eval_argmax':epred}).hist(ax=ax[1][1])\n",
    "plt.show()\n",
    "pd.DataFrame({'test':score_func(ppred, norm=False)}).describe()\n",
    "#pd.DataFrame({'eval':score_func(eppred)})\n",
    "#pd.DataFrame({'ppred':score_func(ppred), 'eppred':score_func(eppred)}).describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": false,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "218px",
    "left": "1647.38px",
    "right": "20px",
    "top": "114px",
    "width": "230px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
