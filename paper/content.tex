\section{Introduction}
Efficiently identifying relations between companies based on 10k filings ... support analysts.

FEIII Challenge 2017\footnote{\url{https://ir.nist.gov/feiii/}}

% from webpage: Given a 10-K filing, an analyst asks, does Company Y, mentioned in this filing, play the role R with respect to filing Company X? Rather than simply answering "yes" or "no", a system responds by providing all the mentions of Company Y in Company X's 10-K filing, with context sentences. These triples are then in ordered by the likelihood that the context accurately defines the relationship or role R between X and Y.

\section{Description of the Data}


source of sentences (10K/Q filings, 25 documents)

\subsection{Inter Annotator Agreement}
The quality of annotations is estimated using Cohen's kappa. The inter annotator agreement (IAA) between two experts is defined as
$$
\kappa = \frac{p_0-p_e}{1-p_e},
$$
where $p_0$ is the proportion of labels with agreement, and $p_e$ the statistical chance of random agreement.

\begin{figure}
	\includegraphics[width=1in]{placeholder}
	\caption{$\kappa$ IAA (upper triangular matrix) and number of commonly rated triples (lower triangular matrix)}
	\label{fig:iaa}
\end{figure}

\Fref{fig:iaa} shows the $\kappa$ for each pair of experts, as well as the number of overlapping labels. Most triplets (60\%) aren't represented in this figure, since they only received a rating by one expert and very few by more than two. The weighted average of $\overline{k}<0.5$ and few overlapping annotations are not ideal for a reliable development and evaluation of a system. For all experiments each triplet's rounded average rating is considered.

\subsection{Preparing the Dataset}

avg and clip annotator scores, lemmatise sentences, tfidf bow

\section{Ranking Algorithm}

\section{Evaluation and Conclusion}
The system's performance is measured by the Normalised Discounted Cumulative Gain (NDCG). The rank at position $p$ is calculated by
\begin{equation}
NDCG_p = \frac{DCG_p}{IDCG_p},\;
DCG_p = rel_1 + \sum_{i=2}^{p} \frac{rel_i}{\log_2(i+1)}
\end{equation}
where $DCG_p$ is the Discounted Cumulative Gain (DCG) when ordering items based on a given score, $IDCG_p$ the ideal DCG, and $rel_i$ the relevance of an item at position $i$ as depicted by the experts.

